{"meta":{"title":"青木的博客","subtitle":null,"description":null,"author":"freeman","url":"https://qingmu.io"},"pages":[{"title":"如何构建springcloud微服务中的异常处理体系","date":"2018-08-20T11:18:33.000Z","updated":"2018-08-21T04:19:48.196Z","comments":true,"path":"images/How-to-handle-exceptions-gracefully-in-springcloud.html","permalink":"https://qingmu.io/images/How-to-handle-exceptions-gracefully-in-springcloud.html","excerpt":"需求 对于我们的任何系统而言一般分为正常的业务流程和异常业务流程 我们希望业务在编写正常的业务逻辑的时候，无需去考虑处理异常的业务流程，异常对于正常的业务是完全分离的，透明的。 我们希望前端也能有一套异常处理体系（在前后端分离下尤为重要） 目标 搭建异常处理体系流程，统一的进行异常的管理和对应的处理（包括前后端） 利用spring提供的全局异常处理器完成后端的server异常统一处理 利用zuul的ErrorFilter统一处理网关相关异常 利用Feign对异常的处理方式，及其扩展，完成服务调服务(S2S)时候异常透明的传递。 利用dvs 的 app.use 方法注册自己的全局异常处理器插件，完成前端的异常流程体系","text":"需求 对于我们的任何系统而言一般分为正常的业务流程和异常业务流程 我们希望业务在编写正常的业务逻辑的时候，无需去考虑处理异常的业务流程，异常对于正常的业务是完全分离的，透明的。 我们希望前端也能有一套异常处理体系（在前后端分离下尤为重要） 目标 搭建异常处理体系流程，统一的进行异常的管理和对应的处理（包括前后端） 利用spring提供的全局异常处理器完成后端的server异常统一处理 利用zuul的ErrorFilter统一处理网关相关异常 利用Feign对异常的处理方式，及其扩展，完成服务调服务(S2S)时候异常透明的传递。 利用dvs 的 app.use 方法注册自己的全局异常处理器插件，完成前端的异常流程体系 异常类型的定义 都说是异常处理体系了，当然最离不开的就是Exception,由于在java中的异常能够打断正常的业务流程。向上抛出，利用这里一点，我们可以在最上层，对抛出的异常进行捕捉，可以统一的进行异常的管理和对应的处理 在java中要拥有被抛的权利，必须继承Exception相关的类，而这些类中有一个特别符合我们的预期，那就是RuntimeException,即运行时异常。 既然是通过异常的向上抛机制来统一处理异常，那么就离不开自定义一些个异常类型，根据实际的开发经验得出，我们可以使用少量自定义异常 + code（然鹅，code大部分时候没暖用） + message（主要是message才有用完成整个的异常处理 实际情况中"},{"title":"jvm options","date":"2018-09-26T07:48:32.000Z","updated":"2018-11-19T08:59:38.248Z","comments":true,"path":"images/jvm-options.html","permalink":"https://qingmu.io/images/jvm-options.html","excerpt":"","text":"https://chriswhocodes.com/hotspot_option_differences.html UseContainerSupport 由于busybox的ps 导致依赖组件有点小瑕疵所以需要update一下ps的依赖 12345678910ps: unrecognized option: pBusyBox v1.28.4 (2018-05-30 10:45:57 UTC) multi-call binary.Usage: ps [-o COL1,COL2=HEADER]Show list of processes -o COL1,COL2=HEADER Select columns for displayThe target pid (11) does not exist! 执行下面命令修复 1apk add --update procps 如果需要用到telnet 则需要安装一下 busybox-extras 1apk add busybox-extras"},{"title":"","date":"2018-11-14T08:48:51.835Z","updated":"2018-11-14T08:48:51.835Z","comments":true,"path":"images/prometheus/p.json","permalink":"https://qingmu.io/images/prometheus/p.json","excerpt":"","text":"{\"__inputs\":[{\"name\":\"DS_MAYIXIAOKE\",\"label\":\"mayixiaoke\",\"description\":\"\",\"type\":\"datasource\",\"pluginId\":\"prometheus\",\"pluginName\":\"Prometheus\"}],\"__requires\":[{\"type\":\"grafana\",\"id\":\"grafana\",\"name\":\"Grafana\",\"version\":\"5.3.2\"},{\"type\":\"panel\",\"id\":\"graph\",\"name\":\"Graph\",\"version\":\"5.0.0\"},{\"type\":\"datasource\",\"id\":\"prometheus\",\"name\":\"Prometheus\",\"version\":\"5.0.0\"},{\"type\":\"panel\",\"id\":\"singlestat\",\"name\":\"Singlestat\",\"version\":\"5.0.0\"}],\"annotations\":{\"list\":[{\"builtIn\":1,\"datasource\":\"-- Grafana --\",\"enable\":true,\"hide\":true,\"iconColor\":\"rgba(0, 211, 255, 1)\",\"name\":\"Annotations & Alerts\",\"type\":\"dashboard\"}]},\"description\":\"Dashboard for Spring Boot2 Statistics(by micrometer-prometheus).\",\"editable\":true,\"gnetId\":6756,\"graphTooltip\":0,\"id\":null,\"iteration\":1542184899449,\"links\":[],\"panels\":[{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":0},\"id\":54,\"panels\":[],\"title\":\"Basic Statistics\",\"type\":\"row\"},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":true,\"colors\":[\"rgba(245, 54, 54, 0.9)\",\"#5195ce\",\"rgba(50, 172, 45, 0.97)\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"decimals\":1,\"editable\":true,\"error\":false,\"format\":\"s\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":false,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":3,\"w\":6,\"x\":0,\"y\":1},\"height\":\"\",\"id\":52,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"70%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"process_uptime_seconds{application=\\\"$application\\\", instance=\\\"$instance\\\"}\",\"format\":\"time_series\",\"intervalFactor\":2,\"legendFormat\":\"\",\"metric\":\"\",\"refId\":\"A\",\"step\":14400}],\"thresholds\":\"\",\"title\":\"Uptime\",\"transparent\":false,\"type\":\"singlestat\",\"valueFontSize\":\"80%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":true,\"colors\":[\"rgba(50, 172, 45, 0.97)\",\"rgba(237, 129, 40, 0.89)\",\"rgba(245, 54, 54, 0.9)\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"decimals\":1,\"editable\":true,\"error\":false,\"format\":\"percent\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":true,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":6,\"w\":5,\"x\":6,\"y\":1},\"id\":58,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"70%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"sum(jvm_memory_used_bytes{application=\\\"$application\\\", instance=\\\"$instance\\\", area=\\\"heap\\\"})*100/sum(jvm_memory_max_bytes{application=\\\"$application\\\",instance=\\\"$instance\\\", area=\\\"heap\\\"})\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"\",\"refId\":\"A\",\"step\":14400}],\"thresholds\":\"70,90\",\"title\":\"Heap Used\",\"type\":\"singlestat\",\"valueFontSize\":\"70%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":true,\"colors\":[\"rgba(50, 172, 45, 0.97)\",\"rgba(237, 129, 40, 0.89)\",\"rgba(245, 54, 54, 0.9)\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"decimals\":1,\"editable\":true,\"error\":false,\"format\":\"percent\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":true,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":6,\"w\":5,\"x\":11,\"y\":1},\"id\":60,\"interval\":null,\"links\":[],\"mappingType\":2,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"70%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"},{\"from\":\"-99999999999999999999999999999999\",\"text\":\"N/A\",\"to\":\"0\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"sum(jvm_memory_used_bytes{application=\\\"$application\\\", instance=\\\"$instance\\\", area=\\\"nonheap\\\"})*100/sum(jvm_memory_max_bytes{application=\\\"$application\\\",instance=\\\"$instance\\\", area=\\\"nonheap\\\"})\",\"format\":\"time_series\",\"intervalFactor\":2,\"legendFormat\":\"\",\"refId\":\"A\",\"step\":14400}],\"thresholds\":\"70,90\",\"title\":\"Non-Heap Used\",\"type\":\"singlestat\",\"valueFontSize\":\"70%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"},{\"op\":\"=\",\"text\":\"x\",\"value\":\"\"}],\"valueName\":\"current\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":6,\"w\":8,\"x\":16,\"y\":1},\"id\":66,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"process_files_open{application=\\\"$application\\\", instance=\\\"$instance\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Open Files\",\"refId\":\"A\"},{\"expr\":\"process_files_max{application=\\\"$application\\\", instance=\\\"$instance\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Max Files\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Process Open Files\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"locale\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":true,\"colors\":[\"rgba(245, 54, 54, 0.9)\",\"#5195ce\",\"rgba(50, 172, 45, 0.97)\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"decimals\":null,\"editable\":true,\"error\":false,\"format\":\"dateTimeAsIso\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":false,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":3,\"w\":6,\"x\":0,\"y\":4},\"height\":\"\",\"id\":56,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"70%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"process_start_time_seconds{application=\\\"$application\\\", instance=\\\"$instance\\\"}*1000\",\"format\":\"time_series\",\"intervalFactor\":2,\"legendFormat\":\"\",\"metric\":\"\",\"refId\":\"A\",\"step\":14400}],\"thresholds\":\"\",\"title\":\"Start time\",\"transparent\":false,\"type\":\"singlestat\",\"valueFontSize\":\"70%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":12,\"x\":0,\"y\":7},\"id\":95,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"system_cpu_usage{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"System CPU Usage\",\"refId\":\"A\"},{\"expr\":\"process_cpu_usage{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Process CPU Usage\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"CPU Usage\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":12,\"x\":12,\"y\":7},\"id\":96,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"system_load_average_1m{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Load Average [1m]\",\"refId\":\"A\"},{\"expr\":\"system_cpu_count{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"CPU Core Size\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Load Average\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":14},\"id\":48,\"panels\":[],\"title\":\"JVM Statistics - Memory\",\"type\":\"row\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":8,\"w\":8,\"x\":0,\"y\":15},\"id\":85,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"minSpan\":null,\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"repeat\":\"memory_pool_heap\",\"repeatDirection\":\"h\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"jvm_memory_used_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"$memory_pool_heap\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Used\",\"refId\":\"C\"},{\"expr\":\"jvm_memory_committed_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"$memory_pool_heap\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Commited\",\"refId\":\"A\"},{\"expr\":\"jvm_memory_max_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"$memory_pool_heap\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Max\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"$memory_pool_heap (heap)\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"bytes\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":8,\"w\":12,\"x\":12,\"y\":15},\"id\":80,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(jvm_classes_unloaded_total{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Classes Unloaded\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Classes Unloaded\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":8,\"w\":8,\"x\":0,\"y\":23},\"id\":88,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"minSpan\":null,\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"repeat\":\"memory_pool_nonheap\",\"repeatDirection\":\"h\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"jvm_memory_used_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"$memory_pool_nonheap\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Used\",\"refId\":\"C\"},{\"expr\":\"jvm_memory_committed_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"$memory_pool_nonheap\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Commited\",\"refId\":\"A\"},{\"expr\":\"jvm_memory_max_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"$memory_pool_nonheap\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Max\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"$memory_pool_nonheap (non-heap)\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"bytes\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":12,\"x\":12,\"y\":23},\"id\":83,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"jvm_buffer_memory_used_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"mapped\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Used Bytes\",\"refId\":\"A\"},{\"expr\":\"jvm_buffer_total_capacity_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"mapped\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Capacity Bytes\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Mapped Buffers\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":8,\"w\":12,\"x\":12,\"y\":30},\"id\":78,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(jvm_gc_memory_allocated_bytes_total{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"allocated\",\"refId\":\"A\"},{\"expr\":\"irate(jvm_gc_memory_promoted_bytes_total{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"promoted\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Memory Allocate/Promote\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"bytes\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"decimals\":0,\"fill\":1,\"gridPos\":{\"h\":8,\"w\":12,\"x\":0,\"y\":31},\"id\":50,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"jvm_classes_loaded{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Classes Loaded\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Classes Loaded\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"decimals\":0,\"format\":\"locale\",\"label\":\"\",\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":12,\"x\":0,\"y\":39},\"id\":82,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"jvm_buffer_memory_used_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"direct\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Used Bytes\",\"refId\":\"A\"},{\"expr\":\"jvm_buffer_total_capacity_bytes{instance=\\\"$instance\\\", application=\\\"$application\\\", id=\\\"direct\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Capacity Bytes\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Direct Buffers\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":8,\"w\":12,\"x\":0,\"y\":46},\"id\":68,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"jvm_threads_daemon{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Daemon\",\"refId\":\"A\"},{\"expr\":\"jvm_threads_live{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Live\",\"refId\":\"B\"},{\"expr\":\"jvm_threads_peak{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Peak\",\"refId\":\"C\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Threads\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":54},\"id\":72,\"panels\":[],\"title\":\"JVM Statistics - GC\",\"type\":\"row\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":10,\"w\":12,\"x\":0,\"y\":55},\"id\":74,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":false,\"hideEmpty\":true,\"hideZero\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(jvm_gc_pause_seconds_count{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\" []\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"GC Count\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"locale\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":10,\"w\":12,\"x\":12,\"y\":55},\"id\":76,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":false,\"hideEmpty\":true,\"hideZero\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(jvm_gc_pause_seconds_sum{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\" []\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"GC Stop the World Duration\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"s\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":65},\"id\":34,\"panels\":[],\"title\":\"HikariCP Statistics\",\"type\":\"row\"},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":false,\"colors\":[\"#299c46\",\"rgba(237, 129, 40, 0.89)\",\"#d44a3a\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"format\":\"none\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":false,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":4,\"w\":4,\"x\":0,\"y\":66},\"id\":44,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"50%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"hikaricp_connections{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"\",\"refId\":\"A\"}],\"thresholds\":\"\",\"title\":\"Connections Size\",\"type\":\"singlestat\",\"valueFontSize\":\"80%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":8,\"w\":20,\"x\":4,\"y\":66},\"id\":36,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"hideEmpty\":true,\"hideZero\":false,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":true,\"steppedLine\":false,\"targets\":[{\"expr\":\"hikaricp_connections_active{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Active\",\"refId\":\"B\"},{\"expr\":\"hikaricp_connections_idle{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Idle\",\"refId\":\"A\"},{\"expr\":\"hikaricp_connections_pending{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Pending\",\"refId\":\"C\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Connections\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":false,\"colors\":[\"#299c46\",\"rgba(237, 129, 40, 0.89)\",\"#d44a3a\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"format\":\"none\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":false,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":4,\"w\":4,\"x\":0,\"y\":70},\"id\":46,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"50%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"hikaricp_connections_timeout_total{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"\",\"refId\":\"A\"}],\"thresholds\":\"\",\"title\":\"Connection Timeout Count\",\"type\":\"singlestat\",\"valueFontSize\":\"80%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":6,\"w\":8,\"x\":0,\"y\":74},\"id\":38,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"hikaricp_connections_creation_seconds_sum{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"} / hikaricp_connections_creation_seconds_count{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Creation Time\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Connection Creation Time\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"s\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":6,\"w\":8,\"x\":8,\"y\":74},\"id\":42,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"hikaricp_connections_usage_seconds_sum{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"} / hikaricp_connections_usage_seconds_count{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Usage Time\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Connection Usage Time\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"s\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":6,\"w\":8,\"x\":16,\"y\":74},\"id\":40,\"legend\":{\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"hikaricp_connections_acquire_seconds_sum{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"} / hikaricp_connections_acquire_seconds_count{instance=\\\"$instance\\\", application=\\\"$application\\\", pool=\\\"$hikaricp\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Acquire Time\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Connection Acquire Time\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"s\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":80},\"id\":18,\"panels\":[],\"title\":\"HTTP Statistics\",\"type\":\"row\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":24,\"x\":0,\"y\":81},\"id\":4,\"legend\":{\"alignAsTable\":true,\"avg\":false,\"current\":false,\"max\":false,\"min\":false,\"rightSide\":true,\"show\":true,\"total\":false,\"values\":false},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(http_server_requests_seconds_count{instance=\\\"$instance\\\", application=\\\"$application\\\", uri!~\\\".*actuator.*\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\" [] - \",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Request Count\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"decimals\":null,\"format\":\"none\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":24,\"x\":0,\"y\":88},\"id\":2,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":false,\"max\":true,\"min\":true,\"rightSide\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(http_server_requests_seconds_sum{instance=\\\"$instance\\\", application=\\\"$application\\\", exception=~\\\"None|none\\\", uri!~\\\".*actuator.*\\\"}[5m]) / irate(http_server_requests_seconds_count{instance=\\\"$instance\\\", application=\\\"$application\\\", exception=~\\\"None|none\\\", uri!~\\\".*actuator.*\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\" [] - \",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Response Time\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"s\",\"label\":\"\",\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":95},\"id\":22,\"panels\":[],\"title\":\"Tomcat Statistics\",\"type\":\"row\"},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":false,\"colors\":[\"#299c46\",\"rgba(237, 129, 40, 0.89)\",\"#d44a3a\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"format\":\"locale\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":false,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":4,\"w\":4,\"x\":0,\"y\":96},\"id\":28,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"50%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"tomcat_global_error_total{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"\",\"refId\":\"A\"}],\"thresholds\":\"\",\"title\":\"Total Error Count\",\"type\":\"singlestat\",\"valueFontSize\":\"80%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"decimals\":0,\"fill\":1,\"gridPos\":{\"h\":7,\"w\":9,\"x\":4,\"y\":96},\"id\":24,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"tomcat_sessions_active_current{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"active sessions\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Active Sessions\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"decimals\":null,\"format\":\"none\",\"label\":\"\",\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"decimals\":null,\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":11,\"x\":13,\"y\":96},\"id\":26,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"irate(tomcat_global_sent_bytes_total{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Sent Bytes\",\"refId\":\"A\"},{\"expr\":\"irate(tomcat_global_received_bytes_total{instance=\\\"$instance\\\", application=\\\"$application\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Recieved Bytes\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Sent & Recieved Bytes\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"bytes\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"cacheTimeout\":null,\"colorBackground\":false,\"colorValue\":false,\"colors\":[\"#299c46\",\"rgba(237, 129, 40, 0.89)\",\"#d44a3a\"],\"datasource\":\"${DS_MAYIXIAOKE}\",\"format\":\"locale\",\"gauge\":{\"maxValue\":100,\"minValue\":0,\"show\":false,\"thresholdLabels\":false,\"thresholdMarkers\":true},\"gridPos\":{\"h\":3,\"w\":4,\"x\":0,\"y\":100},\"id\":32,\"interval\":null,\"links\":[],\"mappingType\":1,\"mappingTypes\":[{\"name\":\"value to text\",\"value\":1},{\"name\":\"range to text\",\"value\":2}],\"maxDataPoints\":100,\"nullPointMode\":\"connected\",\"nullText\":null,\"postfix\":\"\",\"postfixFontSize\":\"50%\",\"prefix\":\"\",\"prefixFontSize\":\"50%\",\"rangeMaps\":[{\"from\":\"null\",\"text\":\"N/A\",\"to\":\"null\"}],\"sparkline\":{\"fillColor\":\"rgba(31, 118, 189, 0.18)\",\"full\":false,\"lineColor\":\"rgb(31, 120, 193)\",\"show\":false},\"tableColumn\":\"\",\"targets\":[{\"expr\":\"tomcat_threads_config_max{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"\",\"refId\":\"A\"}],\"thresholds\":\"\",\"title\":\"Thread Config Max\",\"type\":\"singlestat\",\"valueFontSize\":\"80%\",\"valueMaps\":[{\"op\":\"=\",\"text\":\"N/A\",\"value\":\"null\"}],\"valueName\":\"current\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":13,\"x\":0,\"y\":103},\"id\":30,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":false,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"expr\":\"tomcat_threads_current{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Current thread\",\"refId\":\"A\"},{\"expr\":\"tomcat_threads_busy{instance=\\\"$instance\\\", application=\\\"$application\\\"}\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"Current thread busy\",\"refId\":\"B\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"Threads\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"collapsed\":false,\"gridPos\":{\"h\":1,\"w\":24,\"x\":0,\"y\":110},\"id\":8,\"panels\":[],\"title\":\"Logback Statistics\",\"type\":\"row\"},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":12,\"x\":0,\"y\":111},\"id\":6,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"alias\":\"\",\"expr\":\"irate(logback_events_total{instance=\\\"$instance\\\", application=\\\"$application\\\", level=\\\"info\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"info\",\"rawSql\":\"SELECT\\n $__time(time_column),\\n value1\\nFROM\\n metric_table\\nWHERE\\n $__timeFilter(time_column)\\n\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"INFO logs\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"none\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":12,\"x\":12,\"y\":111},\"id\":10,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"alias\":\"\",\"expr\":\"irate(logback_events_total{instance=\\\"$instance\\\", application=\\\"$application\\\", level=\\\"error\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"error\",\"rawSql\":\"SELECT\\n $__time(time_column),\\n value1\\nFROM\\n metric_table\\nWHERE\\n $__timeFilter(time_column)\\n\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"ERROR logs\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"none\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":8,\"x\":0,\"y\":118},\"id\":14,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"alias\":\"\",\"expr\":\"irate(logback_events_total{instance=\\\"$instance\\\", application=\\\"$application\\\", level=\\\"warn\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"warn\",\"rawSql\":\"SELECT\\n $__time(time_column),\\n value1\\nFROM\\n metric_table\\nWHERE\\n $__timeFilter(time_column)\\n\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"WARN logs\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"none\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":8,\"x\":8,\"y\":118},\"id\":16,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"alias\":\"\",\"expr\":\"irate(logback_events_total{instance=\\\"$instance\\\", application=\\\"$application\\\", level=\\\"debug\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"debug\",\"rawSql\":\"SELECT\\n $__time(time_column),\\n value1\\nFROM\\n metric_table\\nWHERE\\n $__timeFilter(time_column)\\n\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"DEBUG logs\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"none\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}},{\"aliasColors\":{},\"bars\":false,\"dashLength\":10,\"dashes\":false,\"datasource\":\"${DS_MAYIXIAOKE}\",\"fill\":1,\"gridPos\":{\"h\":7,\"w\":8,\"x\":16,\"y\":118},\"id\":20,\"legend\":{\"alignAsTable\":true,\"avg\":true,\"current\":true,\"max\":true,\"min\":true,\"show\":true,\"total\":true,\"values\":true},\"lines\":true,\"linewidth\":1,\"links\":[],\"nullPointMode\":\"null\",\"percentage\":false,\"pointradius\":5,\"points\":false,\"renderer\":\"flot\",\"seriesOverrides\":[],\"spaceLength\":10,\"stack\":false,\"steppedLine\":false,\"targets\":[{\"alias\":\"\",\"expr\":\"irate(logback_events_total{instance=\\\"$instance\\\", application=\\\"$application\\\", level=\\\"trace\\\"}[5m])\",\"format\":\"time_series\",\"intervalFactor\":1,\"legendFormat\":\"trace\",\"rawSql\":\"SELECT\\n $__time(time_column),\\n value1\\nFROM\\n metric_table\\nWHERE\\n $__timeFilter(time_column)\\n\",\"refId\":\"A\"}],\"thresholds\":[],\"timeFrom\":null,\"timeShift\":null,\"title\":\"TRACE logs\",\"tooltip\":{\"shared\":true,\"sort\":0,\"value_type\":\"individual\"},\"type\":\"graph\",\"xaxis\":{\"buckets\":null,\"mode\":\"time\",\"name\":null,\"show\":true,\"values\":[]},\"yaxes\":[{\"format\":\"none\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true},{\"format\":\"short\",\"label\":null,\"logBase\":1,\"max\":null,\"min\":null,\"show\":true}],\"yaxis\":{\"align\":false,\"alignLevel\":null}}],\"refresh\":false,\"schemaVersion\":16,\"style\":\"dark\",\"tags\":[],\"templating\":{\"list\":[{\"allValue\":null,\"current\":{},\"datasource\":\"${DS_MAYIXIAOKE}\",\"hide\":0,\"includeAll\":false,\"label\":\"Application\",\"multi\":false,\"name\":\"application\",\"options\":[],\"query\":\"label_values(jvm_classes_loaded, application)\",\"refresh\":1,\"regex\":\"\",\"skipUrlSync\":false,\"sort\":1,\"tagValuesQuery\":\"\",\"tags\":[],\"tagsQuery\":\"\",\"type\":\"query\",\"useTags\":false},{\"allValue\":null,\"current\":{},\"datasource\":\"${DS_MAYIXIAOKE}\",\"hide\":0,\"includeAll\":false,\"label\":\"Instance\",\"multi\":false,\"name\":\"instance\",\"options\":[],\"query\":\"label_values(jvm_classes_loaded{application=\\\"$application\\\"}, instance)\",\"refresh\":1,\"regex\":\"\",\"skipUrlSync\":false,\"sort\":1,\"tagValuesQuery\":\"\",\"tags\":[],\"tagsQuery\":\"\",\"type\":\"query\",\"useTags\":false},{\"allValue\":null,\"current\":{},\"datasource\":\"${DS_MAYIXIAOKE}\",\"hide\":0,\"includeAll\":false,\"label\":\"HikariCP-Pool\",\"multi\":false,\"name\":\"hikaricp\",\"options\":[],\"query\":\"label_values(hikaricp_connections{instance=\\\"$instance\\\", application=\\\"$application\\\"}, pool)\",\"refresh\":1,\"regex\":\"\",\"skipUrlSync\":false,\"sort\":1,\"tagValuesQuery\":\"\",\"tags\":[],\"tagsQuery\":\"\",\"type\":\"query\",\"useTags\":false},{\"allValue\":null,\"current\":{},\"datasource\":\"${DS_MAYIXIAOKE}\",\"hide\":0,\"includeAll\":true,\"label\":\"Memory Pool (heap)\",\"multi\":false,\"name\":\"memory_pool_heap\",\"options\":[],\"query\":\"label_values(jvm_memory_used_bytes{application=\\\"$application\\\", instance=\\\"$instance\\\", area=\\\"heap\\\"},id)\",\"refresh\":1,\"regex\":\"\",\"skipUrlSync\":false,\"sort\":1,\"tagValuesQuery\":\"\",\"tags\":[],\"tagsQuery\":\"\",\"type\":\"query\",\"useTags\":false},{\"allValue\":null,\"current\":{},\"datasource\":\"${DS_MAYIXIAOKE}\",\"hide\":0,\"includeAll\":true,\"label\":\"Memory Pool (nonheap)\",\"multi\":false,\"name\":\"memory_pool_nonheap\",\"options\":[],\"query\":\"label_values(jvm_memory_used_bytes{application=\\\"$application\\\", instance=\\\"$instance\\\", area=\\\"nonheap\\\"},id)\",\"refresh\":1,\"regex\":\"\",\"skipUrlSync\":false,\"sort\":1,\"tagValuesQuery\":\"\",\"tags\":[],\"tagsQuery\":\"\",\"type\":\"query\",\"useTags\":false}]},\"time\":{\"from\":\"now-1h\",\"to\":\"now\"},\"timepicker\":{\"refresh_intervals\":[\"5s\",\"10s\",\"30s\",\"1m\",\"5m\",\"15m\",\"30m\",\"1h\",\"2h\",\"1d\"],\"time_options\":[\"5m\",\"15m\",\"1h\",\"6h\",\"12h\",\"24h\",\"2d\",\"7d\",\"30d\"]},\"timezone\":\"\",\"title\":\"Spring Boot Statistics\",\"uid\":\"fN8UrMamz\",\"version\":1}"}],"posts":[{"title":"Zuul源码分析(2)Filter分析","slug":"Zuul-processing-flow-and-business-extension-point-2","date":"2018-11-26T15:19:17.000Z","updated":"2018-11-26T05:10:31.622Z","comments":true,"path":"2018/11/26/Zuul-processing-flow-and-business-extension-point-2/","link":"","permalink":"https://qingmu.io/2018/11/26/Zuul-processing-flow-and-business-extension-point-2/","excerpt":"前言在前一篇文件中我们分析了zuul对Filter请求了不同的阶段划分了多个生命周期即FilterType。接下来我们继续分析每一个FilterType的具体的Filter有哪些，他们都干了什么。 ZuulFilters运行流程图 前面我们分析完了zuul的一个生命周期，下面我们在来仔细的看一下每个生命周期具体使用到的Filter","text":"前言在前一篇文件中我们分析了zuul对Filter请求了不同的阶段划分了多个生命周期即FilterType。接下来我们继续分析每一个FilterType的具体的Filter有哪些，他们都干了什么。 ZuulFilters运行流程图 前面我们分析完了zuul的一个生命周期，下面我们在来仔细的看一下每个生命周期具体使用到的Filter Pre 同样你可以在spring-cloud-starter-netflix-zuul-2.0.2.RELEASE包中找到我们的用到的代码片段。 图中被圈起来的代码就是zuul默认激活的Filter，接下来我们分别看下他们都在干嘛。 我们用debug的方式看看zuul激活的Pre的Filter 可以看到我们一共有7个PreFilter，除开两个我们自定义的Filter剩下5个都是zuul自带的，下面我们挨个看一下这些Filer到底干了些嘛事情。 一下我们只贴run()中的代码。 ServletDetectionFilter(顺序 SERVLET_DETECTION_FILTER_ORDER = -3) 这个Filter主要是爬电请求是否来自于DispatcherServlet,并标记servlet的类型。123456789101112131415@Overridepublic Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); if (!(request instanceof HttpServletRequestWrapper) &amp;&amp; isDispatcherServletRequest(request)) &#123; ctx.set(IS_DISPATCHER_SERVLET_REQUEST_KEY, true); &#125; else &#123; ctx.set(IS_DISPATCHER_SERVLET_REQUEST_KEY, false); &#125; return null;&#125;private boolean isDispatcherServletRequest(HttpServletRequest request) &#123; return request.getAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null;&#125; Servlet30WrapperFilter（顺序 SERVLET_30_WRAPPER_FILTER_ORDER = -2） 由于在zuul 1.2.2中存在一个错误，其中HttpServletRequestWrapper.getRequest返回一个包装请求而不是原始请求。这个Filter主要是目的是为了修复这个问题对HttpServletRequestWrapper进行包装，并覆盖 HttpServletRequestWrapper.getRequest.12345678910111213141516171819202122232425262728293031@Overridepublic Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); // 如果是已经包装过的类 if (request instanceof HttpServletRequestWrapper) &#123; // 反射取得HttpServletRequest request = (HttpServletRequest) ReflectionUtils.getField(this.requestField,request); // 重新包装之后设置到ctx中 ctx.setRequest(new Servlet30RequestWrapper(request)); &#125; // 这里其实就是使用了我们在前面Filter设置的IS_DISPATCHER_SERVLET_REQUEST_KEY的值。 else if (RequestUtils.isDispatcherServletRequest()) &#123; ctx.setRequest(new Servlet30RequestWrapper(request)); &#125; return null;&#125; // Servlet30RequestWrapper.java 这个类其实很简单 就是修复zuul 1.2.2中存在一个错误 class Servlet30RequestWrapper extends HttpServletRequestWrapper &#123; private HttpServletRequest request; Servlet30RequestWrapper(HttpServletRequest request) &#123; super(request); this.request = request; &#125; @Override public HttpServletRequest getRequest() &#123; return this.request; &#125; &#125; FormBodyWrapperFilter（顺序 FORM_BODY_WRAPPER_FILTER_ORDER = -1） 该类主要是处理两种Content-Type,我们先看一下shouldFilter， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Overridepublic boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String contentType = request.getContentType(); // 如果contextType则不进行处理 if (contentType == null) &#123; return false; &#125; // 这里很直观的可以看到主要是处理表单数据支持两种mediaType // 第一种是：APPLICATION_FORM_URLENCODED // 第二中是 DispatcherServlet &amp;&amp; MULTIPART_FORM_DATA try &#123; MediaType mediaType = MediaType.valueOf(contentType); return MediaType.APPLICATION_FORM_URLENCODED.includes(mediaType) || (isDispatcherServletRequest(request) &amp;&amp; MediaType.MULTIPART_FORM_DATA.includes(mediaType)); &#125; catch (InvalidMediaTypeException ex) &#123; return false; &#125;&#125;public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); FormBodyRequestWrapper wrapper = null; // 同理如果是被包装过的 if (request instanceof HttpServletRequestWrapper) &#123; // 反射取得HttpServletRequest HttpServletRequest wrapped = (HttpServletRequest) ReflectionUtils.getField(this.requestField, request); //重新包装 wrapper = new FormBodyRequestWrapper(wrapped); // 反射覆盖request字段 ReflectionUtils.setField(this.requestField, request, wrapper); // 如果是通过`/zuul` 的servlet进来的请求 if (request instanceof ServletRequestWrapper) &#123; // 反射覆盖request字段 ReflectionUtils.setField(this.servletRequestField, request, wrapper); &#125;&#125;// 如果没有被包装过，直接包装一下即可else &#123; wrapper = new FormBodyRequestWrapper(request); ctx.setRequest(wrapper);&#125;if (wrapper != null) &#123; // 将content-type放置到ctx中。 ctx.getZuulRequestHeaders().put(\"content-type\", wrapper.getContentType());&#125;return null;&#125; 这里的FormBodyRequestWrapper代码毕竟多，就不展开看了，有兴趣的老哥可以自己去翻阅。 DebugFilter（顺序 DEBUG_FILTER_ORDER = 1） 这个类主要是判断用户是否携带debug参数，如果携带就设置一些标志位，就不展开了。PreDecorationFilter（顺序 PRE_DECORATION_FILTER_ORDER = 5） 这个类的代码行数相对较多，但是他确实只干两件事儿。设置serviceId,设置Header，都在为后面的具体route做准备。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Overridepublic Object run() &#123;RequestContext ctx = RequestContext.getCurrentContext();final String requestURI = this.urlPathHelper.getPathWithinApplication(ctx.getRequest());// 通过URI获取到对应的路由信息//比如我们的请求是 mch-service/get 那么获取到的就是mch-servie为serviceId的路由Route route = this.routeLocator.getMatchingRoute(requestURI);// 如果匹配到有路由才进行处理if (route != null) &#123; // 获取到location，如果是静态路由配置为（http://xxx）,如果是动态服务发现路由则是serviceId String location = route.getLocation(); if (location != null) &#123; // 添加path（/get）到ctx中方便后面直接使用 ctx.put(REQUEST_URI_KEY, route.getPath()); // 添加PROXY_KEY到ctx中方便后面直接使用 ctx.put(PROXY_KEY, route.getId()); // 如果你配置了相关路由信息的header 将在这里处理 if (!route.isCustomSensitiveHeaders()) &#123; this.proxyRequestHelper .addIgnoredHeaders(this.properties.getSensitiveHeaders().toArray(new String[0])); &#125; else &#123; this.proxyRequestHelper.addIgnoredHeaders(route.getSensitiveHeaders().toArray(new String[0])); &#125; // 取得getRetryable并放入ctx if (route.getRetryable() != null) &#123; ctx.put(RETRYABLE_KEY, route.getRetryable()); &#125; //判断是否是配置的静态路由(http://xx.xx.com/users)，而非服务发现的服务 if (location.startsWith(HTTP_SCHEME+\":\") || location.startsWith(HTTPS_SCHEME+\":\")) &#123; ctx.setRouteHost(getUrl(location)); ctx.addOriginResponseHeader(SERVICE_HEADER, location); &#125; else if (location.startsWith(FORWARD_LOCATION_PREFIX)) &#123; ctx.set(FORWARD_TO_KEY, StringUtils.cleanPath(location.substring(FORWARD_LOCATION_PREFIX.length()) + route.getPath())); ctx.setRouteHost(null); return null; &#125; else &#123; // 设置serviceID，并清空静态路由的Host ctx.set(SERVICE_ID_KEY, location); ctx.setRouteHost(null); ctx.addOriginResponseHeader(SERVICE_ID_HEADER, location); &#125; // ... &#125;&#125;else &#123; // 由于我们会在自定义的PRE路由设置好白名单UrlList 所有这里几乎走不过来 log.warn(\"No route found for uri: \" + requestURI); ...&#125;return null;&#125; RouteFilter 前置走了这么久，总算来到我们的具体请求发起阶段了，我们可以从下图看到至少两个信息。第一个信息是zuul内置了3个RouteFilter，第二个是Zuul默认支持使用apacheHttpClient和okttp发起请求。 下面我们就来具体的看一下这三个RouteFilter都在分别在做什么事情。RibbonRoutingFilter（顺序 RIBBON_ROUTING_FILTER_ORDER = 10） 我们分析的前置的Pre设置的相关信息都会在这里用到 先看RibbonRoutingFilter.shouldFilter 12345678910@Overridepublic boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); // 首先单独看看ctx.getRouteHost() == null &amp;&amp; ctx.get(SERVICE_ID_KEY) != null // 结合上一个Filter设置的信息，很直观的能想到如果是静态路由配置，Ribbon压根管不着，直接不支持处理。 return (ctx.getRouteHost() == null &amp;&amp; ctx.get(SERVICE_ID_KEY) != null // 这里判断了ctx中的sendZuulResponse是否为true，该值默认为true， //可想而知如果我们不想走RibbonRoutingFilter，则在PreFilter中调用ctx.setSendZuulResponse(false)即可。 &amp;&amp; ctx.sendZuulResponse());&#125; 在看具体的run方法，具体路由的操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394@Overridepublic Object run() &#123; RequestContext context = RequestContext.getCurrentContext(); this.helper.addIgnoredHeaders(); try &#123; // 这里buildCommandContext方法主要是获取前置的Pre设置到ctx中的相关参数，并构造一个RibbonCommandContext返回 RibbonCommandContext commandContext = buildCommandContext(context); // forward内部其实也是委托给了ribbonCommandFactory的实现者去进行具体调用， ClientHttpResponse response = forward(commandContext); // 设置结果 其实就是将结果放到ctx（threadLocal中的zuulResponse属性）进行结果传递。 setResponse(response); return response; &#125; catch (ZuulException ex) &#123; throw new ZuulRuntimeException(ex); &#125; catch (Exception ex) &#123; throw new ZuulRuntimeException(ex); &#125;&#125;protected RibbonCommandContext buildCommandContext(RequestContext context) &#123; //...其他代码 // 这里取出来serviceId -&gt; mch-service String serviceId = (String) context.get(SERVICE_ID_KEY); // 这里取出来retryable Boolean retryable = (Boolean) context.get(RETRYABLE_KEY); // 该值并没有设置过，永远为null Object loadBalancerKey = context.get(LOAD_BALANCER_KEY); // 在此方法可以看成是String uri = (String) context.get(REQUEST_URI_KEY); String uri = this.helper.buildZuulRequestURI(request); // remove double slashes uri = uri.replace(\"//\", \"/\"); long contentLength = useServlet31 ? request.getContentLengthLong(): request.getContentLength(); // 获取完成相关参数构建请求对象 return new RibbonCommandContext(serviceId, verb, uri, retryable, headers, params, requestEntity, this.requestCustomizers, contentLength, loadBalancerKey);&#125;protected ClientHttpResponse forward(RibbonCommandContext context) throws Exception &#123;...// 将Context传入到具体的实现中进行包装，返回具体的包装好httpclient的cmmand,而这个command其实就HystrixExecutable接口。// Zuul提供的默认实现有（HttpClientRibbonCommandFactory,OkHttpRibbonCommandFactory,RestClientRibbonCommandFactory）RibbonCommand command = this.ribbonCommandFactory.create(context);try &#123; // 执行调用并获取到Htpp响应结果 ClientHttpResponse response = command.execute(); this.helper.appendDebug(info, response.getRawStatusCode(), response.getHeaders()); return response;&#125;catch (HystrixRuntimeException ex) &#123; // 异常处理 return handleException(info, ex);&#125;&#125;// 可以看到这里只有http请求异常时，才会触发protected ClientHttpResponse handleException(Map&lt;String, Object&gt; info, HystrixRuntimeException ex) throws ZuulException &#123;int statusCode = HttpStatus.INTERNAL_SERVER_ERROR.value();Throwable cause = ex;String message = ex.getFailureType().toString();ClientException clientException = findClientException(ex);if (clientException == null) &#123; clientException = findClientException(ex.getFallbackException());&#125;if (clientException != null) &#123; if (clientException .getErrorType() == ClientException.ErrorType.SERVER_THROTTLED) &#123; statusCode = HttpStatus.SERVICE_UNAVAILABLE.value(); &#125; cause = clientException; message = clientException.getErrorType().toString();&#125;info.put(\"status\", String.valueOf(statusCode));// 包装了相关信息并向上抛出。throw new ZuulException(cause, \"Forwarding error\", statusCode, message);&#125;// 设置结果protected void setResponse(ClientHttpResponse resp) throws ClientException, IOException &#123;RequestContext.getCurrentContext().set(\"zuulResponse\", resp);// 一下方法的调用会将返回的body的inputStream设置到ctx// context.setResponseDataStream(entity); 方便后面的fiter使用this.helper.setResponse(resp.getRawStatusCode(), resp.getBody() == null ? null : resp.getBody(), resp.getHeaders());&#125; 这个地方比较复杂，如果你还没理清楚，建议debug配合我的注解跟几次就十分清晰了。 SimpleHostRoutingFilter （顺序 SIMPLE_HOST_ROUTING_FILTER_ORDER = 100） 这里我不打算分析这个hostrouteFilter，因为在实际应用中我们的业务很少过静态路由设置。我们这里看一下他会处理那些请求即可123456@Overridepublic boolean shouldFilter() &#123; // 从Ctx中获取Pre路由中这种的静态如有主机 如果有，并且需要进行发送响应到客户端 return RequestContext.getCurrentContext().getRouteHost() != null &amp;&amp; RequestContext.getCurrentContext().sendZuulResponse();&#125; SendForwardFilter （顺序 SIMPLE_HOST_ROUTING_FILTER_ORDER = 500） 这个SendForwardFilter其实就调用了我们熟悉的HttpServletRquest.getRequestDispatcher.forward(ctx.getRequest(), ctx.getResponse())基本用不上。1234567891011121314151617181920@Overridepublic Object run() &#123; try &#123; RequestContext ctx = RequestContext.getCurrentContext(); String path = (String) ctx.get(FORWARD_TO_KEY); RequestDispatcher dispatcher = ctx.getRequest().getRequestDispatcher(path); if (dispatcher != null) &#123; ctx.set(SEND_FORWARD_FILTER_RAN, true); if (!ctx.getResponse().isCommitted()) &#123; // 熟悉的forward dispatcher.forward(ctx.getRequest(), ctx.getResponse()); ctx.getResponse().flushBuffer(); &#125; &#125; &#125; catch (Exception ex) &#123; ReflectionUtils.rethrowRuntimeException(ex); &#125; return null;&#125; PostFilter 路由完成之后的结果会走到这里来。LocationRewriteFilter （顺序 SEND_RESPONSE_FILTER_ORDER - 100 = 1000 - 100 = 900） 主要处理3XX重定向请求，基本用不上，不多说。1234567@Overridepublic boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); int statusCode = ctx.getResponseStatusCode(); //这里主要是处理HTTP CODE return HttpStatus.valueOf(statusCode).is3xxRedirection();&#125; SendResponseFilter（顺序 SEND_RESPONSE_FILTER_ORDER = 1000）12345678910111213@Overridepublic Object run() &#123;try &#123; // 添加响应头信息addResponseHeaders(); // 写会结果到请求发起方writeResponse();&#125;catch (Exception ex) &#123; //异常向上抛出 ReflectionUtils.rethrowRuntimeException(ex);&#125;return null;&#125; SendErrorFilter(顺序 SEND_ERROR_FILTER_ORDER = 0） 在实际业务中我们一般采用直接继承该类的方式来轻松扩展它，完成业务相关异常的信息转换。1234567@Overridepublic boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); // 由于异常会向上抛出的同时会设置到ctx中，这里统一全局处理掉网关抛出的异常。 return ctx.getThrowable() != null &amp;&amp; !ctx.getBoolean(SEND_ERROR_FILTER_RAN, false);&#125;","categories":[],"tags":[{"name":"zuul","slug":"zuul","permalink":"https://qingmu.io/tags/zuul/"},{"name":"微服务","slug":"微服务","permalink":"https://qingmu.io/tags/微服务/"},{"name":"源码","slug":"源码","permalink":"https://qingmu.io/tags/源码/"}]},{"title":"Zuul源码分析(1)生命周期","slug":"Zuul-processing-flow-and-business-extension-point","date":"2018-11-15T15:19:17.000Z","updated":"2018-11-25T17:05:20.516Z","comments":true,"path":"2018/11/15/Zuul-processing-flow-and-business-extension-point/","link":"","permalink":"https://qingmu.io/2018/11/15/Zuul-processing-flow-and-business-extension-point/","excerpt":"前言 Zuul在Spring Cloud Netfilx 体系中扮演着接入者网关的角色。 本质上来说Zuul本身就是一系列的filters, 可以类比Servlet框架的Filter。按照生命周期我们可以分为四种类型（pre,route,post,err）分别对应请求过程。你可以从com.netflix.zuul.FilterProcessor类里面找到所有的生命周期处理。 为什么我们要去了解它？比如我们想在网关统一对用户进行鉴权，进行JWT的解析和参数转换，比如我们想实现自己的httpClient，再比如我们想在后端业务微服务返回的结果内进行一些特别的处理，比如脱敏啊，比如去掉一些字段啊。 Zuul每个周期的流转过程 请求流程","text":"前言 Zuul在Spring Cloud Netfilx 体系中扮演着接入者网关的角色。 本质上来说Zuul本身就是一系列的filters, 可以类比Servlet框架的Filter。按照生命周期我们可以分为四种类型（pre,route,post,err）分别对应请求过程。你可以从com.netflix.zuul.FilterProcessor类里面找到所有的生命周期处理。 为什么我们要去了解它？比如我们想在网关统一对用户进行鉴权，进行JWT的解析和参数转换，比如我们想实现自己的httpClient，再比如我们想在后端业务微服务返回的结果内进行一些特别的处理，比如脱敏啊，比如去掉一些字段啊。 Zuul每个周期的流转过程 请求流程 maven 在maven中加入sprin cloud 对zuul的gav 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 然后我们在idea中展开jar包 可以看到有个标准的spring.factorices描述文件，内容如下 123org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.netflix.zuul.ZuulServerAutoConfiguration,\\org.springframework.cloud.netflix.zuul.ZuulProxyAutoConfiguration 仔细看有没有觉得很熟悉。有没有想起zuul的两个注解，没错就是@EnableZuulServer和 @EnableZuulProxy，你可以点击这里查看他们的区别简单的说，ZuulProxyAutoConfiguration是ZuulServerAutoConfiguration的子类,当使用@EnableZuulProxy 时会启用父类的filter和自己的filter。 那么下面我们先来看一下ZuulServerAutoConfiguration 都激活了些什么东西。这里主要分析主流程和关键Bean 下面代码截取自spring-cloud-starter-netflix-zuul-2.0.2.RELEASE,弟131-138行。 在这里他激活了一个叫ZuulServlet的类，并把这个类注册给了spring。 123456789//。public ServletRegistrationBean zuulServlet() &#123; ServletRegistrationBean&lt;ZuulServlet&gt; servlet = new ServletRegistrationBean&lt;&gt;(new ZuulServlet(), this.zuulProperties.getServletPattern()); // The whole point of exposing this servlet is to provide a route that doesn't // buffer requests. servlet.addInitParameter(\"buffer-requests\", \"false\"); return servlet;&#125; 我们继续追下去看看这个ZuulServlet到底是干了些什么。 下面代码截取自spring-cloud-starter-netflix-zuul-2.0.2.RELEASE,来自类com.netflix.zuul.http.ZuulServlet。去掉了一些干扰阅读的代码。 在分析代码之前我们先看RequestContext这么个鬼东西，他贯穿了zuul的处理的生命周期，核心作用就是通过ThreadLocal变量将每一给filter处理结果存储起来，进行传递到下一个filter。 123456789101112131415161718public class RequestContext extends ConcurrentHashMap&lt;String, Object&gt; &#123; protected static final ThreadLocal&lt;? extends RequestContext&gt; threadLocal = new ThreadLocal&lt;RequestContext&gt;() &#123; @Override protected RequestContext initialValue() &#123; try &#123; return contextClass.newInstance(); &#125; catch (Throwable e) &#123; throw new RuntimeException(e); &#125; &#125; &#125;; // 直接返回的就是ThreadLocal变量 public static RequestContext getCurrentContext() &#123; RequestContext context = threadLocal.get(); return context; &#125; &#125; 核心流程处理直接看到service方法，可以看到这里直接覆写了HttpServlet.service，我们知道所有的请求都会经过service方法，所以这里这里相当于是拦截了所有的请求. 先介绍一下每个route分别定位是什么： preFilter：我们可以写一个我们自己的preFilter，在preFilter里面处理user的鉴权，JWT是否有效，参数转换，限流等到前置工作都能在此处实现，并可以通过向外抛出相关异常的方式传递到errorFilter中。 routeFilter：route阶段是发起http具体请求的阶段，可想而知如果我们使用ribbon做负载均衡的调用的话，ribbon一定会有一个route阶段的filter来处理具体的请求。没错这个类就RibbonRoutingFilter 它将zuul和ribbon连接起来了，而DiscoveryClientRouteLocator又将ribbon和eurake又连接起来，这样通过从RequestContext中获取到serviceid，就能完成服务发现和服务调用啦。当然你可以新增一个自己的routeFilter来完成自己的http OR 其他协议的请求调用。 post: post阶段，这个阶段我们能从RequestContext中获取到route请求完成的结果，可以对ResponseBody进行一些特殊处理，也能添加一下个性化的HttpHeader 接下呢是try…catch三连.轻松的定义了四条路由链处理： 第一条链（正确的处理过程): pre -&gt; route -&gt; post 第二条链（在pre过程中抛出异常): pre -&gt; error -&gt; post 一般在pre抛出的异常都是我们自定义的异常。 第三条链（在route过程中抛出异常): pre -&gt;route -&gt;error -&gt;post 在实际使用中，一般是url编写错误，service-id书写有误，或者远程调用发生错误。 第四条链（在post过程中抛出异常): pre -&gt;route -&gt;post -&gt;error 一般在post抛出异常都是由于客户这边强制关闭了连接比如说客户请求过程中断网啊，比如说下载的excel过大导致客户关闭浏览器啊。 ZuulServlet123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class ZuulServlet extends HttpServlet &#123; // 将实际的路由处理委托给了zuulRunner，即可我们前面提到的四个生命周期的具体调用者就是这位老哥了。后面讲具体讲到 private ZuulRunner zuulRunner; // 正常的 @Override public void init(ServletConfig config) throws ServletException &#123; // other code... // 在这里激活了zuulRuner zuulRunner = new ZuulRunner(bufferReqs); &#125; @Override public void service(javax.servlet.ServletRequest servletRequest, javax.servlet.ServletResponse servletResponse) throws ServletException, IOException &#123; try &#123; RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); try &#123; preRoute(); &#125; catch (ZuulException e) &#123; error(e); postRoute(); return; &#125; try &#123; route(); &#125; catch (ZuulException e) &#123; error(e); postRoute(); return; &#125; try &#123; postRoute(); &#125; catch (ZuulException e) &#123; error(e); return; &#125; &#125; catch (Throwable e) &#123; error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); &#125; finally &#123; RequestContext.getCurrentContext().unset(); &#125; &#125; //委托给zuulRunner void postRoute() throws ZuulException &#123; zuulRunner.postRoute(); &#125; //委托给zuulRunner void route() throws ZuulException &#123; zuulRunner.route(); &#125; //委托给zuulRunner void preRoute() throws ZuulException &#123; zuulRunner.preRoute(); &#125; //委托给zuulRunner void init(HttpServletRequest servletRequest, HttpServletResponse servletResponse) &#123; zuulRunner.init(servletRequest, servletResponse); &#125; //委托给zuulRunner，并将异常放入ThreadLocal 进行传递 void error(ZuulException e) &#123; RequestContext.getCurrentContext().setThrowable(e); zuulRunner.error(); &#125;&#125; ZuulRunner 可以看到zuulRunner好像也没干实际干事儿，又将调用委托给了一个单例对象。 12345678910111213141516171819public class ZuulRunner &#123; public void postRoute() throws ZuulException &#123; FilterProcessor.getInstance().postRoute(); &#125; public void route() throws ZuulException &#123; FilterProcessor.getInstance().route(); &#125; public void preRoute() throws ZuulException &#123; FilterProcessor.getInstance().preRoute(); &#125; public void error() &#123; FilterProcessor.getInstance().error(); &#125;&#125; FilterProcessor 接下来我们在看FilterProcessor这个类，这个类总算是干活儿的小老铁了。 一下代码截取自FilterProcessor。有没有觉得很熟悉呀,这里我们用肉眼就能看出来是每个方法在调用哪个filter，调用方式也是很简单粗暴，传入调用的filterType。那么如果你需要debugZuul的生命周期，断点打在这部分方法上是不是极好的呢？ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public void postRoute() throws ZuulException &#123; try &#123; runFilters(\"post\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_POST_FILTER_\" + e.getClass().getName()); &#125; &#125; /** * runs all \"error\" filters. These are called only if an exception occurs. Exceptions from this are swallowed and logged so as not to bubble up. */ public void error() &#123; try &#123; runFilters(\"error\"); &#125; catch (Throwable e) &#123; logger.error(e.getMessage(), e); &#125; &#125; /** * Runs all \"route\" filters. These filters route calls to an origin. * * @throws ZuulException if an exception occurs. */ public void route() throws ZuulException &#123; try &#123; runFilters(\"route\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_ROUTE_FILTER_\" + e.getClass().getName()); &#125; &#125; /** * runs all \"pre\" filters. These filters are run before routing to the orgin. * * @throws ZuulException */ public void preRoute() throws ZuulException &#123; try &#123; runFilters(\"pre\"); &#125; catch (ZuulException e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new ZuulException(e, 500, \"UNCAUGHT_EXCEPTION_IN_PRE_FILTER_\" + e.getClass().getName()); &#125; &#125; 这个类有个关键的方法 runFilters 这个方法传入的的是一个filterType即要进行route类型，即会传入（pre,route,post,err）这些个类型按照上面分析的流程进行调用 12345678910111213141516171819public Object runFilters(String filterType) throws Throwable &#123; if (RequestContext.getCurrentContext().debugRouting()) &#123; Debug.addRoutingDebug(\"Invoking &#123;\" + sType + \"&#125; type filters\"); &#125; boolean bResult = false; // 这里是获取到同一个类型的Filter集合 List&lt;ZuulFilter&gt; list = FilterLoader.getInstance().getFiltersByType(sType); if (list != null) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; ZuulFilter zuulFilter = list.get(i); //这里又把调用委托到出去了 实际上我们可以看成 zuulFilter.run()；调用 Object result = processZuulFilter(zuulFilter); if (result != null &amp;&amp; result instanceof Boolean) &#123; bResult |= ((Boolean) result); &#125; &#125; &#125; return bResult;&#125; 到处我们就将filter的请求调用周期分析完毕。下一篇文章我们将具体分析到每个阶段具体的Filter都干了些什么。","categories":[],"tags":[{"name":"zuul","slug":"zuul","permalink":"https://qingmu.io/tags/zuul/"},{"name":"微服务","slug":"微服务","permalink":"https://qingmu.io/tags/微服务/"},{"name":"源码","slug":"源码","permalink":"https://qingmu.io/tags/源码/"}]},{"title":"如何构建一个监控体系","slug":"How-to-build-a-monitoring-system","date":"2018-11-13T15:43:52.000Z","updated":"2018-11-21T16:41:17.163Z","comments":true,"path":"2018/11/13/How-to-build-a-monitoring-system/","link":"","permalink":"https://qingmu.io/2018/11/13/How-to-build-a-monitoring-system/","excerpt":"前言 对于整个微服务系统而言。一套及时的报警通知，可视化监控，是必不可少的。 整体架构图","text":"前言 对于整个微服务系统而言。一套及时的报警通知，可视化监控，是必不可少的。 整体架构图 全局异常处理器 在我们的微服务中，所有的业务在进行实际操作之前都会进行业务的防御性校验。 如果发现发生一些意外情况,我们通过向上抛出业务异常的的方式进行传递。 在整个业务开发过程中，会有大量的业务校验不通过或者不满足的情况发生，这时候我们需要提示给到用户，给调用方，通知哪个环节使用的不合理导致问题。比如以下场景: 用户添加了已经下架的商品到购物车 123if (!product.getIsOn()) &#123; throw new BizException(\"商品已下架,不能加入购物车\");&#125; 用户对已经下架的商品进行了数量更新操作 1234if (!product.getIsOn()) &#123; cartItemMapper.deleteByProjectIdAndUserIdAndSkuId(projectId, userId, skuId); throw new BizException(\"该商品已下架,已自动从购物车移除\");&#125; 用户取消非待支付的订单 123if (orderStatus != Order.OrderStatus.待支付) &#123; throw new BizException(\"只有待支付订单才能取消\");&#125; 当遇到业务校验不通过时，因为有全局异常处理器兜底，我们只需要向上抛出我们的业务异常即可。 带来的好处 首先是业务代码中完全将异常业务流程和正常业务流程进行了完全的分离，代码的可读性大大提高。 其次避免了写业务逻辑时的不清楚到底在 哪层进行try catch，哪层代码不try catch。避免了在业务代码中由于每个人理解不懂导致的凌乱的try catch。 第三，异常被统一管理起来了，可以进行方便的统一处理，比如,我们可以在发生异常的时候,发送邮件告诉到我们的负责这个业务的小哥（这其实也是完成DevOps自动化链中必不可少的一环）。可以统一处理返回到用户到调用端的payload。 第四，对于具体的业务而言通过basejar的引入就能完成自动的激活和配置。任何特殊要求。可控性高。 GlobalExceptionHandler 说了这么多，附上全局异常处理器的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166@RestControllerAdvice@Slf4j@EnableConfigurationProperties(GlobalExceptionHandler.EmailProperties.class)public class GlobalExceptionHandler &#123; @Autowired private SmtpServer smtpServer; @Autowired private GlobalExceptionHandler.EmailProperties emailProperties; @Value(\"$&#123;spring.application.name&#125;\") private String applicationName; @Autowired Environment environment; //创建一个单线程的线程池 public static final ExecutorService cachedThreadPool = Executors.newSingleThreadExecutor(new NamedThreadFactory(\"email\", true)); // 只用一个定长队列 缓冲需要发送出去的邮件 @Qualifier(\"emailQueue\") @Autowired private BlockingQueue&lt;EmailMate&gt; emailQueue; @Bean @ConditionalOnMissingBean(SmtpServer.class) public SmtpServer smtpServer(GlobalExceptionHandler.EmailProperties emailProperties) throws Exception &#123; return SmtpServer.create() .host(emailProperties.smtp.host) .port(emailProperties.smtp.port) .ssl(true) .auth(emailProperties.smtp.username, emailProperties.smtp.password) .debugMode(emailProperties.smtp.debugMode) .buildSmtpMailServer(); &#125; @Bean @ConditionalOnMissingBean(name = \"emailQueue\") public BlockingQueue&lt;EmailMate&gt; emailMates(GlobalExceptionHandler.EmailProperties emailProperties) throws Exception &#123; if (emailProperties.enabled) &#123; return new ArrayBlockingQueue&lt;&gt;(emailProperties.queueSize); &#125; return new ArrayBlockingQueue&lt;&gt;(0); &#125; // 启动发邮件线程 消费email queue @PostConstruct public void startEmail() &#123; if (!emailProperties.enabled) return; final String[] activeProfiles = environment.getActiveProfiles(); final String activeProfile = activeProfiles.length == 1 ? activeProfiles[0] : environment.getDefaultProfiles()[0]; String[] to = emailProperties.smtp.to.toArray(new String[emailProperties.smtp.to.size()]); final String from = emailProperties.smtp.from; cachedThreadPool.execute(() -&gt; &#123; Thread thread = Thread.currentThread(); thread.setName(\"Email-Consumer-Thread\"); while (!Thread.currentThread().isInterrupted()) &#123; try &#123; final EmailMate take = emailQueue.take(); final String message = take.message; try (final StringWriter out = new StringWriter(); final PrintWriter printWriter = new PrintWriter(out); final SendMailSession session = smtpServer.createSession();) &#123; session.open(); take.throwable.printStackTrace(printWriter); session.sendMail(Email.create() .from(from) .to(to) .subject(\"[\" + activeProfile + \"]应用 [\" + applicationName + \"] 异常报警！\") .htmlMessage( String.format(\"&lt;html&gt;&lt;META http-equiv=Content-Type content=\\\"text/html; \" + \"charset=utf-8\\\"&gt;&lt;body&gt;%s&lt;br /&gt;%s&lt;/body&gt;&lt;/html&gt;\", message, out.toString().replaceAll(\"(\\r\\n|\\n)\", \"&lt;br /&gt;\")) , \"utf-8\") ); &#125; &#125; catch (Exception e) &#123; log.error(e.getMessage(), e); &#125; &#125; &#125;); &#125; @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public Result handleException(Exception e, HttpServletRequest request, HttpServletResponse response) &#123; writeHeader(response); e = findEx(e); handleCommon(e, request); return Result.builder().code(SysException.FINAL_CODE).message(e.getMessage()).build(); &#125; // 您的其他异常类型处理器 .... private Exception findEx(Throwable throwable) &#123; if (throwable == null) return null; while (true) &#123; if (throwable.getCause() == null) &#123; return (Exception) throwable; &#125; else &#123; throwable = throwable.getCause(); &#125; &#125; &#125; private void handleCommon(Throwable e, HttpServletRequest request) &#123; final String message = \"host:\" + MyUtils.getHost() + \", uri:\" + request.getRequestURI() + \", referrer:\" + request.getHeader(HttpHeaders.REFERER); // 过滤你的不发送邮件的异常 if (e != null &amp;&amp; !(e instanceof BizException)) &#123; // 这里我们使用queue的offer方法 如果队列满了直接丢弃 emailQueue.offer(EmailMate.builder().message(message).throwable(e).build()); &#125; log.error(message, e); &#125; private void writeHeader(HttpServletResponse response) &#123; response.setHeader(HttpHeaders.CONTENT_TYPE, MediaType.APPLICATION_JSON_VALUE); &#125; @Builder @AllArgsConstructor @NoArgsConstructor @Setter @Getter @ToString public static class EmailMate &#123; private Throwable throwable; private String message; &#125; @Setter @Getter @ConfigurationProperties(prefix = \"global.exception.handler.email\") @ToString public static class EmailProperties &#123; private boolean enabled = true; private Smtp smtp = new Smtp(); private int emailQueueSize = 100; private int queueSize = 50; @Setter @Getter @ToString public static class Smtp &#123; private String host = \"默认值\"; private int port = 465; private String username = \"username\"; private String password = \"password\"; private boolean useSSL = true; private boolean debugMode = false; private String from = \"exception@xxx.com\"; private List&lt;String&gt; to = Arrays.asList(\"xxxx@qq.com\"); &#125; &#125;&#125; 在你的业务调用方你可以愉快的在application.yml修改邮件接收人。 这样谁负责的业务，出现异常清苦就能在第一时间收到通知，配合devops链（后面会写一篇）能进行最快速的修复。12345678global: exception: handler: email: smtp: to: - xxx@xxx.com - xxx@xxx.com 微服务监控服务 由于相关性比较大，所以不方便贴代码，这里简单说一下思想的思路。 首先是又个地方存放需要监控的服务名，端口号，需要检测的Uri。该URL最好是能访问到DB。redis等等。 然后是检测服务这个服务的高可用性，可以用zk选主的机制来保证。 然后是发送提醒的间隔，以及业务恢复正常之后的的提醒。 可视化监控Prometheus 是什么截取github上的原句The Prometheus monitoring system and time series database.，可知是携监控和时序数据库一体的新一代开源解决方案，SoundCloud开源，2016 年，Prometheus 正式加入 Cloud Native Computing Foundation，成为受欢迎度仅次于 Kubernetes 的项目，目前在github 已经有2w+ star。 主要特性： 强大的社区，和丰富的插件，为我们的应用接入提供了极大的方便。 采用http协议通信，采用pull的模型，极大的减少了对应用的侵入性。比如我们的springcloud微服务，只需要导入相关jar包即可。 支持动态配置和服务发现。比如从consul和eureka读取我们的微服务list和detail。 使用docker安装Prometheus prometheus的安装通过一条promethues即可完成,根据自己的容器管理工具进行对应的调整即可 1docker run -d -p 9090:9090 --name prometheus -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml 对于prometheus.yml的配置，由于它天生对eureka并不提供服务发现的机制的支持，这里我们需要使用一个适配器来支持服务发现。 这里我们使用eureka-consul-adapter来支持。 使用起来也很简单，只需要在eureka中添加gav依赖坐标即可 12345&lt;dependency&gt; &lt;groupId&gt;at.twinformatics&lt;/groupId&gt; &lt;artifactId&gt;eureka-consul-adapter&lt;/artifactId&gt; &lt;version&gt;$&#123;eureka-consul-adapter.version&#125;&lt;/version&gt;&lt;/dependency&gt; 验证一下是否生效 12345678910111213141516171819# 获取所有服务freemandeMBP:opt freeman$ curl -i http://192.168.0.204:8761/v1/catalog/services&#123;\"ACTIVITY-SERVICE\":[],\"ADDRESS-SERVICE\":[],\"ADMIN-ZUUL-GATEWAY\":[],....&#125;# 获取单个服务详细freemandeMBP:opt freeman$ curl -i http://192.168.0.204:8761/v1/catalog/service/ACTIVITY-SERVICE[&#123; Address: \"192.168.0.204\", Node: \"ACTIVITY-SERVICE\", ServiceAddress: \"192.168.0.204\", ServiceID: \"4c53000573c9:activity-service:8044\", ServicePort: 8044, NodeMeta: &#123; management.port: \"8044\" &#125;, ServiceTags: []&#125;,....] 通过之后我们就可以使用服务发现来机制来让prometheus自动发现我们的微服务，进行指标的采集了。 prometheus.yml的配置如下，其中metrics_path是固定约定好的，server填写的是任意一台eureka的地址和端口 1234567891011121314151617181920212223242526272829303132333435363738394041global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.rule_files: - \"first_rules.yml\"scrape_configs: - job_name: \"prometheus\" static_configs: - targets: [\"localhost:9090\"] - job_name: \"micro-service\" consul_sd_configs: - server: \"eureka1:8761\" metrics_path: /actuator/prometheus relabel_configs: - source_labels: [\"__meta_consul_service\"] regex: \"consul\" action: drop - source_labels: [\"__meta_consul_tags\"] regex: \",(management),\" action: drop - source_labels: [__address__] separator: \":\" regex: \"(.*):(8080)\" target_label: __address__ replacement: \"$&#123;1&#125;:8090\" - source_labels: [\"__meta_consul_service\"] regex: \"(.*)\" target_label: \"job\" replacement: \"$1\" - source_labels: [\"__meta_consul_service\"] regex: \"(.*)\" target_label: \"application\" replacement: \"$1\" - source_labels: [\"__meta_consul_service_id\"] regex: \"(.*)\" target_label: \"instance\" replacement: \"$1\" - source_labels: [\"__meta_consul_tags\"] regex: \",(prod|test|dev),\" target_label: \"group\" replacement: \"$1\" 现在我们来验证下prometheus的服务发现是否正确的发现我们需要采集的微服务节点 打开浏览器访问 http://你的prometheus服务ip:端口/targets 如果配置正确你将看到你的微服务列表，表示我们的promuethus和springcloud服务发现整合完毕了。 Grafana简介 Grafana是一个可视化面板（Dashboard），有着非常漂亮的图表和布局展示，以及丰富的dashboard模板，功能齐全的度量仪表盘和图形编辑器，支持Prometheus作为数据源。 这里我们使用前面配置好的Prometheus作为Grafana的DataSource。 使用docker安装Grafana 官网有提供安装指南 一般使用如下docker命令即可完成安装 1docker run -d -p 3000:3000 grafana/grafana 安装完成之后,访问http://ip:3000 就可以看到UI界面了，第一次登录需要设置下admin账号密码。设置下即可添加数据源 找到如下setting，选择DataSource 选择添加DataSource type选择Prometheus URL填入你的Prometheus的ip:port 注意使用完整的http协议开头。如http://prometheus:9090 其余的如无特殊设置可不填写。直接点击Save&amp;Test即可完成数据源的添加。 添加spring dashboard 选择create -&gt; Import -&gt; 填入如下下面的json 本模板由 模板id 6756 修改而来 你可以点击这里查看原生模板，修改后的模板 效果展示 存走势 G1GC SWT HTTP Reponse Time","categories":[],"tags":[{"name":"Prometheus","slug":"Prometheus","permalink":"https://qingmu.io/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","permalink":"https://qingmu.io/tags/Grafana/"},{"name":"可视化监控","slug":"可视化监控","permalink":"https://qingmu.io/tags/可视化监控/"},{"name":"监控","slug":"监控","permalink":"https://qingmu.io/tags/监控/"}]},{"title":"记SpringCloud 1.X 升级到2.x","slug":"How-to-upgrade-SpringCloud1-x-to-2-x","date":"2018-10-31T05:32:01.000Z","updated":"2018-11-15T07:45:28.962Z","comments":true,"path":"2018/10/31/How-to-upgrade-SpringCloud1-x-to-2-x/","link":"","permalink":"https://qingmu.io/2018/10/31/How-to-upgrade-SpringCloud1-x-to-2-x/","excerpt":"前言 前后花了两周多个时间完成了 Spring Boot 1.5.6.RELEASE &amp; Spring Cloud Dalston.SR4 升级到 Spring Boot 2.0.6.RELEASE &amp; Spring Cloud Finchley.SR2 &amp; spring-cloud-netflix 2.0.2.RELEASE 的工作。 总结一下遇到的一些问题 一些问题的总结 首先 1.x和2.x的所有的服务注册，服务发现，灰度调用，服务调用，zuul网关等等组件核心都是兼容的。so大胆的升级吧。 其次maven pom变化较大,主要是netifilx的artifactId变化比较多,其余的变化都不是太大，这都可以通过spring-cloud-netflix-dependenciespom中找到。 然后是feign的变化比较大，整个包名发生了变化。 NotBlank,NotEmpty 现在已经纳入了JSR303了，不需要在使用hibernate提供的注解了。 一些建议 建议统一抽象出一个业务服务使用pom依赖项目，并打包发布维护起来，比如我们这里就叫my-server-dependencies的这么一个pom项目。这样做有几个好处： 第一个是通过将版本统一管理起来了，方便对所有的基础服务jar包进行升级，而且能够完成版本的基础依赖管理。 第二个是能够避免掉由于未付项目过多之后导致的依赖版本混乱。 第三个是能够将maven插件统一的配置，比如说docker打包插件,fatjar插件,compiler插件 ，能统一的对他们进行控制和配置，并通过properties暴露出集体的调优指标。","text":"前言 前后花了两周多个时间完成了 Spring Boot 1.5.6.RELEASE &amp; Spring Cloud Dalston.SR4 升级到 Spring Boot 2.0.6.RELEASE &amp; Spring Cloud Finchley.SR2 &amp; spring-cloud-netflix 2.0.2.RELEASE 的工作。 总结一下遇到的一些问题 一些问题的总结 首先 1.x和2.x的所有的服务注册，服务发现，灰度调用，服务调用，zuul网关等等组件核心都是兼容的。so大胆的升级吧。 其次maven pom变化较大,主要是netifilx的artifactId变化比较多,其余的变化都不是太大，这都可以通过spring-cloud-netflix-dependenciespom中找到。 然后是feign的变化比较大，整个包名发生了变化。 NotBlank,NotEmpty 现在已经纳入了JSR303了，不需要在使用hibernate提供的注解了。 一些建议 建议统一抽象出一个业务服务使用pom依赖项目，并打包发布维护起来，比如我们这里就叫my-server-dependencies的这么一个pom项目。这样做有几个好处： 第一个是通过将版本统一管理起来了，方便对所有的基础服务jar包进行升级，而且能够完成版本的基础依赖管理。 第二个是能够避免掉由于未付项目过多之后导致的依赖版本混乱。 第三个是能够将maven插件统一的配置，比如说docker打包插件,fatjar插件,compiler插件 ，能统一的对他们进行控制和配置，并通过properties暴露出集体的调优指标。 1234567891011121314151617181920212223&lt;!--比如说我我在 dependencies 中定义了很多 props,这些是通用的服务配置 --&gt;&lt;properties&gt; &lt;prod.jvm.Xms&gt;1G&lt;/prod.jvm.Xms&gt; &lt;prod.jvm.Xmx&gt;1G&lt;/prod.jvm.Xmx&gt; &lt;prod.jvm.g1.newp&gt;5&lt;/prod.jvm.g1.newp&gt; &lt;prod.jvm.g1.maxp&gt;60&lt;/prod.jvm.g1.maxp&gt;&lt;/properties&gt;&lt;!-- 比如说我们通过可视化监控发现，某个业务服务访问比较多对象生成的比较快,由于默认配置的堆太小，导致GC触发的比较频繁 由于默认的G1MaxNewSizePercent为60%,我们通过可视化监控发现odl区分配的40%堆空间的利用率不到10%。 那么这时候可以通过调节G1的G1MaxNewSizePercent和增大一些JVM的最大内存,以此来减少GC触发频率和更高的资源利用率 那么根据以上结论我们就需要修改一下相关配置。由于我们把这些关键配置都通过props暴露出来了，业务项目只需要如下几个props修改，就完成了我们想要的。 --&gt; &lt;properties&gt; &lt;prod.jvm.Xms&gt;4G&lt;/prod.jvm.Xms&gt; &lt;prod.jvm.Xmx&gt;4G&lt;/prod.jvm.Xmx&gt; &lt;prod.jvm.g1.newp&gt;40&lt;/prod.jvm.g1.newp&gt; &lt;prod.jvm.g1.maxp&gt;80&lt;/prod.jvm.g1.maxp&gt;&lt;/properties&gt; 第四个是能够将一些必带的包默认激活，比如说 lombok spring-boot-starter-actuator micrometer-registry-prometheus 等。 第五个建议是将profiles 统一定义在parent中，这样方便gitlab-ci.yml 文件的统一处理。 POM Change parent 目前最新版是 2.0.6.RELEASE 点击这里获取最新版 这里建议使用2.0.5+的spring boot 不然会有个DataSource的bug导致无法启动12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt;&lt;/parent&gt; application.yml 1234567891011121314 spring: multipart: max-file-size: 10Mb # 旧 servlet: multipart: max-request-size: 10MB max-file-size: 10MB # 新配置# 开启新的指标management: endpoints: web: exposure: include: \"*\" JSR303 org.hibernate.validator.constraints.NotBlank ==&gt; javax.validation.constraints.NotBlank2.org.hibernate.validator.constraints.NotEmpty ==&gt; javax.validation.constraints.NotEmpty ErrorController org.springframework.boot.autoconfigure.web.ErrorController ==&gt; org.springframework.boot.web.servlet.error.ErrorController pom 更新 123456789101112131415161718192021222324252627 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR2&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-dependencies&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; Eureka Server eureka server 需要将artifactId更新 旧的artifactId 是 spring-cloud-starter-eureka-server 新的artifactId spring-cloud-starter-netflix-eureka-server 更新完成之后的完成eurake-server配置如下1234567891011121314151617181920212223 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 为方便prometheus拉取数据的一个eurake到consul的适配器--&gt; &lt;dependency&gt; &lt;groupId&gt;at.twinformatics&lt;/groupId&gt; &lt;artifactId&gt;eureka-consul-adapter&lt;/artifactId&gt; &lt;version&gt;$&#123;eureka-consul-adapter.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; Eureka Client 旧pom 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 更新的pom如下 123456789101112131415161718192021222324252627&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;!--这里排除掉jersey的依赖 spring cloud 会默认构建一个resttpml替代--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jersey.contribs&lt;/groupId&gt; &lt;artifactId&gt;jersey-apache-client4&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; Config client1234567891011&lt;!--旧的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--更新之后的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; FeignFeign的POM更新 上面提到说feign的变化是最大的，如下是具体变化12345678910 &lt;!-- 旧的 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; &lt;!-- 新的 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; Feign 中的注解类 feign 注解变化 org.springframework.cloud.netflix.feign.FeignClient ==&gt; org.springframework.cloud.openfeign.FeignClient org.springframework.cloud.netflix.feign.EnableFeignClients ==&gt; org.springframework.cloud.openfeign.EnableFeignClients feign 默认的jackson配置会导致服务直接调用的抛出如下异常1Can not deserialize value of type java.util.Date from String &quot;2018-11-02T04:14:56.761+0000&quot;: not a valid representation (error: Failed to parse Date value &apos;2018-11-02T04:14:56.761+0000&apos;: Unparseable date: &quot;2018-11-02T04:14:56.761+0000&quot;) 原因是因为默认的jackson日期格式无法解析成yyyy-MM-dd HH:mm:ss， 默认的jackson配置也会把null值的属性序列化，这样会导致无用的字符串开销。所以这里我们需要配置一下fegin默认的Encoder 12345678910111213141516@Beanpublic feign.codec.Encoder feignEncoder() &#123; return new SpringEncoder(() -&gt; httpMessageConverters());&#125;private HttpMessageConverters httpMessageConverters() &#123; ObjectMapper mapper = new ObjectMapper(); mapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); mapper.enable(DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT); mapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); mapper.enable(DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL); mapper.setDateFormat(new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")); mapper.setTimeZone(TimeZone.getTimeZone(\"GMT+8:00\")); // 由于我们的feign只用于对内的请求，所以这里我们只需要使用Jackson的converter,所以new的时候第一个参数填false，排除掉默认的 return new HttpMessageConverters(false,Arrays.asList(new MappingJackson2HttpMessageConverter(mapper)));&#125; #ZUUL The default HTTP client used by Zuul is now backed by the Apache HTTP Client instead of the deprecated Ribbon RestClient. To use RestClient or okhttp3.OkHttpClient, set ribbon.restclient.enabled=true or ribbon.okhttp.enabled=true, respectively. If you would like to customize the Apache HTTP client or the OK HTTP client, provide a bean of type ClosableHttpClient or OkHttpClient. Ribbon 灰度调用 之前有提到过通过扩展ribbon支持灰度，由于2.0的spring boot 默认在eurake的matedata重携带了一些稀奇古怪的东西，导致我们之前的代码不能用了，修改后的结果如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class MetadataAwareRule extends ZoneAvoidanceRule &#123; @Override public Server choose(Object key) &#123; final RibbonFilterContext context = RibbonFilterContextHolder.getCurrentContext(); ILoadBalancer lb = getLoadBalancer(); final List&lt;Server&gt; allServers = lb.getAllServers(); // 存放已打标签但不满足标签的server final List&lt;Server&gt; metaServers = new ArrayList&lt;&gt;(); // 存放未标签的server final List&lt;Server&gt; noMetaServers = new ArrayList&lt;&gt;(); // 匹配成功的server final List&lt;Server&gt; matchedMetaServers = new ArrayList&lt;&gt;(); final Map&lt;String, String&gt; attributes = context.getAttributes(); // 取得接口端传入的参数 final String inputDeveloper = attributes.get(\"developer\"); for (Server server : allServers) &#123; if (server instanceof DiscoveryEnabledServer) &#123; final DiscoveryEnabledServer discoveryEnabledServer = (DiscoveryEnabledServer) server; final Map&lt;String, String&gt; metadata = discoveryEnabledServer.getInstanceInfo().getMetadata(); final String developer = metadata.get(\"developer\"); // 如果没有meta数据 表示是测试服务上的地址 if (developer == null || developer.equals(\"\")) &#123; // 存放并没有打标签的server noMetaServers.add(server); &#125; else &#123; // 如果匹配成功开发者直接调用 if (inputDeveloper != null &amp;&amp; (!\"\".equals(inputDeveloper)) &amp;&amp; developer.equals(inputDeveloper)) &#123; matchedMetaServers.add(server); &#125; else &#123; // 存入server有标签但是不匹配的server metaServers.add(server); &#125; &#125; &#125; &#125; //优先走自定义路由。即满足灰度要求的server if (!matchedMetaServers.isEmpty()) &#123; com.google.common.base.Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(matchedMetaServers, key); if (server.isPresent()) &#123; return server.get(); &#125; else &#123; return null; &#125; &#125; // 如果没有匹配成功的则走 else &#123; if (!noMetaServers.isEmpty()) &#123; com.google.common.base.Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(noMetaServers, key); if (server.isPresent()) &#123; return server.get(); &#125; else &#123; return null; &#125; &#125; else &#123; // 似情况打开 return null;// com.google.common.base.Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(metaServers, key);// if (server.isPresent()) &#123;// return server.get();// &#125; else &#123;// return null;// &#125; &#125; &#125; &#125;&#125;","categories":[],"tags":[]},{"title":"记Kafka的一个BUG，导致整个集群不能工作","slug":"Kafka-bug-Cached-zkVersion-not-equal-to-that-in-zookeeper-broker-not-recovering","date":"2018-10-21T02:28:37.000Z","updated":"2018-11-21T16:39:49.702Z","comments":true,"path":"2018/10/21/Kafka-bug-Cached-zkVersion-not-equal-to-that-in-zookeeper-broker-not-recovering/","link":"","permalink":"https://qingmu.io/2018/10/21/Kafka-bug-Cached-zkVersion-not-equal-to-that-in-zookeeper-broker-not-recovering/","excerpt":"现象 Kafka producer 无法正确的发出任何消息一直抛出Timeout（由于我们业务设计上就把业务时间和mq完全分离了这里，不会导致业务不能正常进行，只会产生业务暂时的不一致性）12345678910111213141516171819java.util.concurrent.TimeoutException: Timeout after waiting for 5000 ms. at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:76) at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29) at com.my.fnc.mq.FncRunner.apply(FncRunner.java:42) at io.goudai.starter.runner.zookeeper.AbstractMultipartRunner$1.doRun(AbstractMultipartRunner.java:76) at io.goudai.starter.runner.zookeeper.AbstractRunner.takeLeadership(AbstractRunner.java:94) at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:537) at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:399) at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:444) at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:64) at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:245) at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:239) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)","text":"现象 Kafka producer 无法正确的发出任何消息一直抛出Timeout（由于我们业务设计上就把业务时间和mq完全分离了这里，不会导致业务不能正常进行，只会产生业务暂时的不一致性）12345678910111213141516171819java.util.concurrent.TimeoutException: Timeout after waiting for 5000 ms. at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:76) at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:29) at com.my.fnc.mq.FncRunner.apply(FncRunner.java:42) at io.goudai.starter.runner.zookeeper.AbstractMultipartRunner$1.doRun(AbstractMultipartRunner.java:76) at io.goudai.starter.runner.zookeeper.AbstractRunner.takeLeadership(AbstractRunner.java:94) at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:537) at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:399) at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:444) at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:64) at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:245) at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:239) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Kafka Consumer 不能正确的消费任何消息 1234567891011121314151617181920org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records. at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:786) at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:734) at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:808) at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:788) at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:204) at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:167) at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:127) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:506) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:353) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:268) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214) at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:190) at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:600) at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1242) at io.goudai.starter.kafka.consumer.KafkaBeanPostProcessor.handleRecord(KafkaBeanPostProcessor.java:236) at io.goudai.starter.kafka.consumer.KafkaBeanPostProcessor.lambda$startConsumer$2(KafkaBeanPostProcessor.java:206) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 检查Kafka Log12345678910&#123;\"log\":\"[2018-10-21 06:21:35,780] INFO [Partition user-auth-confirm-failed-12 broker=1] Shrinking ISR from 1,5,4 to 1,4 (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.780359744Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,790] INFO [Partition user-auth-confirm-failed-12 broker=1] Cached zkVersion [133] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.790651434Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,790] INFO [Partition order-agent-offline-pay-submitted-10 broker=1] Shrinking ISR from 2,1,5 to 2,1 (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.790689985Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,792] INFO [Partition order-agent-offline-pay-submitted-10 broker=1] Cached zkVersion [55] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.79359849Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,793] INFO [Partition payment-fail-2 broker=1] Shrinking ISR from 1,5,4 to 1,4 (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.793623565Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,795] INFO [Partition payment-fail-2 broker=1] Cached zkVersion [133] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.796206037Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,795] INFO [Partition deposit-paid-26 broker=1] Shrinking ISR from 1,5,4 to 1,4 (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.796228348Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,798] INFO [Partition deposit-paid-26 broker=1] Cached zkVersion [160] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.799150335Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,798] INFO [Partition order-agent-stock-notify-success-20 broker=1] Shrinking ISR from 1,5,4 to 1,4 (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.799177669Z\"&#125;&#123;\"log\":\"[2018-10-21 06:21:35,801] INFO [Partition order-agent-stock-notify-success-20 broker=1] Cached zkVersion [133] not equal to that in zookeeper, skip updating ISR (kafka.cluster.Partition)\\r\\n\",\"stream\":\"stdout\",\"time\":\"2018-10-20T22:21:35.801745244Z\"&#125; 可以看出重复最多的日志是 Cached zkVersion xx not equal to that in zookeeper, skip updating ISR 试着将 Cached zkVersion xx not equal to that in zookeeper, skip updating ISR 贴到google搜索 运气真不错，找到了这个 issue https://issues.apache.org/jira/browse/KAFKA-2729 看来蛮多人都遇到了这个问题 然后再去 stackoverflow.com 上搜一下，果然找到了它 https://stackoverflow.com/questions/46644764/kafka-cached-zkversion-not-equal-to-that-in-zookeeper-broker-not-recovering stackoverfolw 上的老哥说到解决方案就是万能的重启。 原问答是这样的This issue is known and tracked in KAFKA-2729 but not solved till now. This happens as far as I know on networks with big delays due to max traffic or some short network outages in a small timeframe. The only solution (afaik) is to restart all brokers. 结论 综上所结论 暂时的解决办法就是万能的重启kafka节点的broker。 想要彻底解决在官方的issus中显示是在kafka1.1.0 中修复的，需要把所有的broker进行升级。 解决问题让业务恢复正常吧 重启所有的broker 由于我们的kafka consumer和producer 在业务实现上都有遇到Exception 自动重启的的机制。So 这里我只重启broker就完成了业务的正常运行了。","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://qingmu.io/tags/kafka/"}]},{"title":"如何构建SpringBoot的Docker镜像","slug":"How-to-run-springcloud-in-docker","date":"2018-08-07T13:21:18.000Z","updated":"2018-11-23T08:02:50.789Z","comments":true,"path":"2018/08/07/How-to-run-springcloud-in-docker/","link":"","permalink":"https://qingmu.io/2018/08/07/How-to-run-springcloud-in-docker/","excerpt":"目标 自定义Dockerfile构建一个生产可用的jre base image 配置maven-docker-plugin插件完成从源码的 打包fatjar -&gt; build docker image with fatjar -&gt; push image 支持docker对JVM相关参数的配置。比如Xmx，Xms，以及完全自定义的java启动参数。 rootfs 说打包之前我们先了解linux内核与发行版操作系统（如centos，ubuntu，debian）之间的关系。 由于linux内核与具体的操作系统是解耦的。即互相不干涉的，docker利用了这个特性，将操作系统的文件打包成一个压缩文件。 在运行时，解压这个压缩包，并通过chroot进行挂载，就完成了容器的内部我们看到的操作系统了。即我们的rootfs。 那么这个和我们docker打包java应用的关系在哪里呢？ 总所周知的是java是又提供打包解决方案的，打包成jar，但是此方案的问题在于我并不能在任何一个环境里面运行直接运行（因为依赖JRE），而每一个操作系统又不一样，这就导致许多环境带来的时间浪费。 结合前面提到了docker打包是把操作系统的文件打包的，所以我们能不能把操作系统+jre+application.jar这三老铁一锅端，全给他打包起来不就解决了吗？没错，这就是我们要构建镜像。 没错我们想到了一个好的办法来解决打包的问题。那我们在来看看这个东西是不是还有啥问题？你看啊，我们最初了发布一个fatjar也就60M，要结合上OS jre岂不是每次都大很多，浪费很多的磁盘，网络传送开销也加大的蛮多。 这个问题的docker中利用了分层文件系统来解决这个问题，即我们的OS JRE 这些不变的东西只会在第一次使用时下载一次或者上传一次，其他时候我们只有变化的application.jar层需要进行上传和下载 最终形态 我们像搭积木一样一层一层的把我们所需要的文件系统叠加起来，就完成了我们想要的Image。","text":"目标 自定义Dockerfile构建一个生产可用的jre base image 配置maven-docker-plugin插件完成从源码的 打包fatjar -&gt; build docker image with fatjar -&gt; push image 支持docker对JVM相关参数的配置。比如Xmx，Xms，以及完全自定义的java启动参数。 rootfs 说打包之前我们先了解linux内核与发行版操作系统（如centos，ubuntu，debian）之间的关系。 由于linux内核与具体的操作系统是解耦的。即互相不干涉的，docker利用了这个特性，将操作系统的文件打包成一个压缩文件。 在运行时，解压这个压缩包，并通过chroot进行挂载，就完成了容器的内部我们看到的操作系统了。即我们的rootfs。 那么这个和我们docker打包java应用的关系在哪里呢？ 总所周知的是java是又提供打包解决方案的，打包成jar，但是此方案的问题在于我并不能在任何一个环境里面运行直接运行（因为依赖JRE），而每一个操作系统又不一样，这就导致许多环境带来的时间浪费。 结合前面提到了docker打包是把操作系统的文件打包的，所以我们能不能把操作系统+jre+application.jar这三老铁一锅端，全给他打包起来不就解决了吗？没错，这就是我们要构建镜像。 没错我们想到了一个好的办法来解决打包的问题。那我们在来看看这个东西是不是还有啥问题？你看啊，我们最初了发布一个fatjar也就60M，要结合上OS jre岂不是每次都大很多，浪费很多的磁盘，网络传送开销也加大的蛮多。 这个问题的docker中利用了分层文件系统来解决这个问题，即我们的OS JRE 这些不变的东西只会在第一次使用时下载一次或者上传一次，其他时候我们只有变化的application.jar层需要进行上传和下载 最终形态 我们像搭积木一样一层一层的把我们所需要的文件系统叠加起来，就完成了我们想要的Image。 Docker Image需求 我们要达到如下预期 镜像比如要足够小（尽量控制在100M以内） 字符集必须要支持中文，不然就乱码了 时区的是UTC+8 字体的支持，不然excel导出会抛出错误 还的支持下imagemagick。 使我们运行在容器中的java进程PID!=1如果Pid=1会有很多问题(如jmap,jstat…等工具无法使用,你可以从这里了解更多 jmap not happy on alpine )这里我们使用Tini来完成这个工作，关于Tini你可以从这里了解更多 What is advantage of Tini? 措施 基于以上要求我们构建出一下镜像 首先使用apline作为基础镜像足够小只有5M 由于alpine自带支持中文的字符集，这里我们只需要将LANG设置为C.UTF-8即可完美的支持中文。 国内软件源首选阿里云啦，顺道配置一下阿里云的镜像源，加速我们的镜像构建速度。 配置UTC+8时区需要安装tzdata，安装完成之后配置一下即可。 目前alpine携带JDK版本为1.80_171。 使用tini 包装java进程。 Dockerfile构建基础java镜像（图中最一层和第二层） 如下的dockerfile是一个完整的dockerfile文件。基于5M大小的alpine镜像构建，apline提供的包管理器是apk，我在这里为了方便使用直接配置了阿里云提供的镜像源，加速构建过程。 12345678910111213FROM alpine:3.8MAINTAINER qingmu 247687009@qq.comENV LANG=C.UTF-8 \\ JAVA_HOME=/usr/lib/jvm/java-1.8-openjdk/jre \\ PATH=$PATH:/usr/lib/jvm/java-1.8-openjdk/jre/bin:/usr/lib/jvm/java-1.8-openjdk/bin \\ TZ=Asia/ShanghaiRUN echo \"\" &gt; /etc/apk/repositories \\&amp;&amp; echo \"https://mirrors.aliyun.com/alpine/v3.8/main/\" &gt;&gt; /etc/apk/repositories \\&amp;&amp; echo \"https://mirrors.aliyun.com/alpine/v3.8/community/\" &gt;&gt; /etc/apk/repositories \\&amp;&amp; apk update &amp;&amp; apk add --no-cache openjdk8-jre ca-certificates tzdata tini \\&amp;&amp; apk add --update procps \\&amp;&amp; rm -rf /var/cache/apk/* \\&amp;&amp; ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone 如你想动手构建自己，将以上Dockerfile文件copy一份，写入Dockerfile文件中执行构建即可。执行以下命令,即可完成属于您自己的镜像，这里需要一点docker的基础知识 12echo 'dockerfile' &gt; Dockerfiledocker build -t freemanliu/openjre . 关于docker build 命令你可以点击这里了解更多更详细的用法。 当然了，你如果不想构建那么也可以使用我在github上写好的，并在dockerhub中autobuild好的镜像。 注意该镜像不包含字体文件，在使用到字体相关的api时，会抛出异常，如对excel导出的操作，这时候我们需要安装一下字体库，我们通过apk库添加十分简单,只需在以上的Dockerfile描述文件中加入一下库即可，其他保持不变。如你还用到了其他相关软件,请google查阅相关库，使用apk包管理器添加即可。 1apk add --no-cache ttf-dejavu 如此我们便得到了一个包含了jre的Image镜像，下面我们继续来构建第三层。 SpringBoot打包fatjar 在配置maven项目的parent为spring-boot-dependencies后，springboot默认在pluginManagement中配置好了 maven-shade-plugin插件我们可以在我们自己具体业务微服务中激活该插件，配置如下： 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置好了插件，插件怎么知道我们的start class是哪个呢？springboot很贴心的提供了一个start-class属性。我们只需要赋值即可 123&lt;properties&gt; &lt;start-class&gt;com.qingmu.account.Application&lt;/start-class&gt;&lt;/properties&gt; 配置完成之后我们可以在命令行执行如下命令，便可完成我们的fatjar的打包。 执行该命令本质上mave插件会将我们所依赖的jar解压并copy到到我们的fatjar中。 1mvn clean package 如配置正确你将在你的target目录中看到${artifactId}.jar 在命令行执行java -jar target/${artifactId}.jar也能正确的启动成功。 Docker打包fatjar镜像（构建第三层） 在前面的的章节，我们完成了JRE镜像和fatjar的构建。接下来我们将完成他们的结合，完成灵魂的升华 ~ ~。 Dockerfile VS Docker-mave-plugin 在java项目中我们至少有两种方式对我们的docker和fatjar进行结合打包成image。 Dockerfile 一种常见的方式是编写Dockerfile，并使用Cli命令行对齐进行相关操作，这也是网上比较多的教程所采用的方法。然而该方法有比较麻烦的问题：第一，如果你的项目较多怎么能，意味着你需要为每一个项目去添加一份dockerfile描述文件，当然这点可以通过自定义maven骨架解决。第二，这么多dockerfile散落在微服务项目的几十上百个仓库中，如果有一天要更新这个dockerfile中的某些内容，就会变得异常的麻烦和难以高效率的解决。 Docker-mave-plugin 这是一个由于com.spotify提供的maven插件，使用它将可以轻松的完成SpringBoot项目的docker镜像打包推送工作。 当然他也能很好的解决以上Dockerfile的问题，不需要Dockerfile描述文件了，我们可以将描述的相关信息写到maven插件中，而maven是支持继承的，以为者我们只需要在我们自己的parent-pom中维护这个docker插件就维护了所有的具体微服务的打包插件了。实际用下来是相当的方便啊。实际项目中也采用的是该方案。 ENTRYPOINT VS CMD ENTRYPOINT和CMD命令最大的不同点，在于使用cmd命令是可以在运行是通过传递参数修改镜像的运行命令的，而ENTRYPOINT命令则是不支持的。 简单的说就是ENTRYPOINT类似编程中的常量，一旦定义好了就无法改变。而cmd则类似与变量，你可以在运行时随时赋值。 一起来看下这个例子，这是一个常见的使用docker打包java应用的dockerfile描述文件,。使用了ENTRYPOINT来指定启动命令。 12345# freemanliu/app:v1.0.0FROM java:8ADD app.jar app.jarEXPOSE 8800ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"] 将这个image启动起来，我们只需要执行如下命令，变可以轻松的运行起来我们的应用。在启动镜像是它会默认执行ENTRYPOINT中所书写的描述。 1docker run -it -rm freemanliu/app:v1.0.0 如果我们想运行的时候不运行默认的命令，比如说我们执行以下命令，进入到容器的sh命令终端。你会发现无效，由于我们是使用的ENTRYPOINT定义的是”常量”，所以你将会看到的结果任然是java进程成功启动。而如果使用的CMD命令，则是可以正确的进入sh终端。 1docker run -it -rm freemanliu/app:v1.0.0 sh 至于CMD也好还是ENTRYPOINT也罢，都可以用，看你的喜好了，我是更喜欢freedom一点的，我推荐CMD 那么好的，基础的东西我们就讨论到这里。 配置POM在具体配置之前我们先总结下需要干些什么：第一步，肯定是先引入插件，不多说。第二步，既然我们想要插件帮我们完成image的push，那的让插件知道我们的私服地址吧，得知道username/password吧，所以第二步我们得配置setting.xml，添加server。第三步，插件有了，私服配好了，接下来就的琢磨插件的配置了吧，所有第三步我们配置插件。第四步，配置完成一个插件之后，我们该考虑一下多环境打包的事儿吧。第四步处理profiles 添加插件到pluginManagement 首先是引入插件，你可以点击这里了解更多插件的信息,虽然他现在极力推崇dockerfile插件，但是真的没这个实用性高啊。 我们得养成一个习惯，在添加任何新的依赖是，先在咱们的parent项目的xxxManagement中先添加上，在真正业务pom中去掉版本号，让parent统一管理依赖的版本号。1234567891011&lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt;&lt;/build&gt; 配置私服 关于私服你可以自己搭建，选择还是比较多,官方的docker-registry,比较知名和完善的Harbor，以及我们的老朋友Nexus3. 自己搭建虽然很方便也很简单，那有没有不用自己维护性能还不错的三方私有仓库选择呢？当然还是有的，毕竟这世上好人还是多，阿里云为我们提供了免费的私有仓库服务，你只需要注册阿里云，控制台搜索容器镜像服务，就能找到他了。 对于经常配置server的老司机来说这一步很简单，但是对于新玩家来说这一步比较复杂，如果你不是很熟悉并且没有配置过maven的setting.xml文件的话，我建议你使用图形化编辑器，找准如下标签插入即可。 为啥~/.m2/settings.xml这是因为maven默认读取的配置目录是当前用户目录下的.m2目录，windows的话你需要找到你当前用户。123456789101112vim ~/.m2/settings.xml# 找到servers标签添加如下如下信息&lt;servers&gt; &lt;server&gt; &lt;id&gt;aliyun-registry&lt;/id&gt; # id将在后面插件中用到 &lt;username&gt;你的私服的username&lt;/username&gt; &lt;password&gt;你私服的密码&lt;/password&gt; &lt;configuration&gt; &lt;email&gt;你的email&lt;/email&gt; &lt;/configuration&gt; &lt;/server&gt;&lt;/servers&gt; 插件配置 在配置插件前，另一个插件git-commit-id-plugin通过该插件我们可以在maven的其他插件中很方便的用到git相关信息，比如获取到当前的git tag。 通用的我们配置的插件默认不激活，写到pluginManagement 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;pl.project13.maven&lt;/groupId&gt; &lt;artifactId&gt;git-commit-id-plugin&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;get-the-git-infos&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;revision&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 使properties扩展到整个maven bulid 周期 Ref: https://github.com/ktoso/maven-git-commit-id-plugin/issues/280 --&gt; &lt;injectAllReactorProjects&gt;true&lt;/injectAllReactorProjects&gt; &lt;dateFormat&gt;yyyyMMddHHmmss&lt;/dateFormat&gt; &lt;!--&lt;useNativeGit&gt;false&lt;/useNativeGit&gt;--&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;dotGitDirectory&gt;$&#123;project.basedir&#125;/.git&lt;/dotGitDirectory&gt; &lt;!--若项目打包类型为pom,是否取消构建;默认值:true;--&gt; &lt;skipPoms&gt;false&lt;/skipPoms&gt; &lt;!--是否生成\"git.properties\"文件;默认值:false;--&gt; &lt;generateGitPropertiesFile&gt;true&lt;/generateGitPropertiesFile&gt; &lt;!--指定\"git.properties\"文件的存放路径(相对于$&#123;project.basedir&#125;的一个路径);--&gt; &lt;generateGitPropertiesFilename&gt;git.properties&lt;/generateGitPropertiesFilename&gt; &lt;!--git描述配置,可选;由JGit提供实现;--&gt; &lt;gitDescribe&gt; &lt;!--是否生成描述属性--&gt; &lt;skip&gt;false&lt;/skip&gt; &lt;!--提交操作未发现tag时,仅打印提交操作ID,--&gt; &lt;always&gt;false&lt;/always&gt; &lt;!--提交操作ID显式字符长度,最大值为:40;默认值:7; 0代表特殊意义;后面有解释; --&gt; &lt;abbrev&gt;40&lt;/abbrev&gt; &lt;!--构建触发时,代码有修改时(即\"dirty state\"),添加指定后缀;默认值:\"\";--&gt; &lt;dirty&gt;-dirty&lt;/dirty&gt; &lt;!--always print using the \"tag-commits_from_tag-g_commit_id-maybe_dirty\" format, even if \"on\" a tag. The distance will always be 0 if you're \"on\" the tag. --&gt; &lt;forceLongFormat&gt;false&lt;/forceLongFormat&gt; &lt;/gitDescribe&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; 在添加插件的时候我们说到应该把通用的东西放到xxxManagement标签中，将变化的内容通过变量的形式抽取出来，完成最大程度的复用。 所以我们对插件的配置也是通用的，所以也是改在Management中完成配置，并抽取变化。具体配置如下图，可能显得有些复杂。由于为了灵活性的需要，我们进行了多次变量取，这里我来详细解释下： 首先properties标签中的大写的变量取值，意思为取得系统上下的属性，至于为什么要这么做呢？是因为为了让我们的镜像在运行是可以通过环境变量的形式对其进行修改优化。仔细看你会发现这些值都是有可能对于不同的硬件服务器有着完全不同的设定。避免了修改java内存及一些相关参数而重写打包镜像，也提供了一个修改的便捷渠道。 接下来再看env标签,有没有觉得眼熟？这里是定义系统环境变量的地方，这里的定义与我们在properties标签中定义的名称一致,可以看到我们在这里有进行一次变量取值，为什么又是变量取值，而不是写死一个值呢？主要出于三点考虑：第一点是方便maven执行mvn clean package -Djvm.Xms=2G 通过命令行传递默认参数。第二点是为了方便具体业务通过在自己的pom重覆盖该参数完成默认参数的修改。第三点当然是为了支持多环境打包准备。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;properties&gt; &lt;docker.jre&gt;freemanliu/openjre&lt;/docker.jre&gt; &lt;docker.jre.version&gt;1.8.0_171&lt;/docker.jre.version&gt; &lt;java.opts&gt; -Dservice.name=$&#123;project.artifactId&#125; \\ -XX:+UnlockExperimentalVMOptions \\ -Xms$&#123;JAVA_HEAP_XMS&#125; \\ -Xmx$&#123;JAVA_HEAP_XMX&#125; \\ -XX:CICompilerCount=$&#123;CI_COMPILER_COUNT&#125; \\ -XX:G1NewSizePercent=$&#123;G1_NEW_SIZE_PERCENT&#125; \\ -XX:G1MaxNewSizePercent=$&#123;G1_MAX_NEW_SIZE_PERCENT&#125; \\ -DEUREKA_SERVER=$&#123;EUREKA_SERVER&#125; \\ -Dspring.profiles.active=$&#123;spring.profile&#125; \\ -Dspring.cloud.config.profile=$&#123;spring.profile&#125; \\ -XX:+UseG1GC \\ -XX:+AggressiveOpts \\ -XX:+UseFastAccessorMethods \\ -XX:+UseStringDeduplication \\ -XX:+UseCompressedOops \\ -XX:+OptimizeStringConcat &lt;/java.opts&gt; &lt;jvm.Xms&gt;1G&lt;/jvm.Xms&gt; &lt;jvm.Xmx&gt;1G&lt;/jvm.Xmx&gt; &lt;g1.new.size.percent&gt;5&lt;/g1.new.size.percent&gt; &lt;g1.max.size.percent&gt;60&lt;/g1.max.size.percent&gt; &lt;pushImage&gt;true&lt;/pushImage&gt; &lt;ci.compiler.count&gt;8&lt;/ci.compiler.count&gt; &lt;eureka.url&gt;$&#123;prod.eureka&#125;&lt;/eureka.url&gt; &lt;spring.profile&gt;test&lt;/spring.profile&gt;&lt;properties&gt;&lt;pluginManagement&gt;&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;imageName&gt; $&#123;docker.repository&#125;/$&#123;docker.registry.name&#125;/$&#123;project.artifactId&#125;:$&#123;git.commit.id.describe-short&#125; &lt;/imageName&gt; &lt;registryUrl&gt;$&#123;docker.repository&#125;&lt;/registryUrl&gt; &lt;workdir&gt;/work&lt;/workdir&gt; &lt;rm&gt;true&lt;/rm&gt; &lt;env&gt; &lt;!--关于G1的一些参数说明您可以从这里获取到 https://www.oracle.com/technetwork/cn/articles/java/g1gc-1984535-zhs.html --&gt; &lt;!--设置时区--&gt; &lt;TZ&gt;Asia/Shanghai&lt;/TZ&gt; &lt;!--初始化堆大小--&gt; &lt;JAVA_HEAP_XMS&gt;$&#123;jvm.Xms&#125;&lt;/JAVA_HEAP_XMS&gt; &lt;!--jvm最大可使用的堆--&gt; &lt;JAVA_HEAP_XMX&gt;$&#123;jvm.Xmx&#125;&lt;/JAVA_HEAP_XMX&gt; &lt;!--设置要用作年轻代大小，最小值的堆百分比。默认值是 Java 堆的 5%，需要使用解锁实验性质的标志-XX:+UnlockExperimentalVMOptions--&gt; &lt;G1_NEW_SIZE_PERCENT&gt;$&#123;g1.new.size.percent&#125;&lt;/G1_NEW_SIZE_PERCENT&gt; &lt;!--设置要用作年轻代大小，最大值的堆百分比。默认值是 Java 堆的 60%，需要使用解锁实验性质的标志-XX:+UnlockExperimentalVMOptions--&gt; &lt;G1_MAX_NEW_SIZE_PERCENT&gt;$&#123;g1.max.size.percent&#125;&lt;/G1_MAX_NEW_SIZE_PERCENT&gt; &lt;!--调整编译线程的数目，我们服务器都是8core配置所以这里统一配置成8--&gt; &lt;CI_COMPILER_COUNT&gt;$&#123;ci.compiler.count&#125;&lt;/CI_COMPILER_COUNT&gt; &lt;!--eureka url 配置--&gt; &lt;EUREKA_SERVER&gt;$&#123;eureka.url&#125;&lt;/EUREKA_SERVER&gt; &lt;JAVA_OPTS&gt;$&#123;java.opts&#125;&lt;/JAVA_OPTS&gt; &lt;/env&gt; &lt;baseImage&gt;$&#123;docker.jre&#125;:$&#123;docker.jre.version&#125;&lt;/baseImage&gt; &lt;cmd&gt; /sbin/tini java $&#123;JAVA_OPTS&#125; -jar $&#123;project.build.finalName&#125;.jar &lt;/cmd&gt; &lt;!--是否推送image--&gt; &lt;pushImage&gt;$&#123;pushImage&#125;&lt;/pushImage&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这里与你的配置的私服id一致--&gt; &lt;serverId&gt;aliyun-registry&lt;/serverId&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt;&lt;plugins&gt;&lt;/pluginManagement&gt; 多环境配置 完成了插件的配置和变量的抽取之后我们具体使用将十分的简单 下面我贴出常见的一些profile1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;profiles&gt;&lt;profile&gt; &lt;!--高度灵活的profile--&gt; &lt;id&gt;docker&lt;/id&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/profile&gt;&lt;profile&gt; &lt;!--prod的profile--&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;base.docker.repository&gt;$&#123;docker.registry&#125;&lt;/base.docker.repository&gt; &lt;eureka.url&gt;$&#123;prod.eureka&#125;&lt;/eureka.url&gt; &lt;g1.new.size.percent&gt;$&#123;g1.new.size.percent&#125;&lt;/g1.new.size.percent&gt; &lt;g1.max.size.percent&gt;$&#123;g1.max.size.percent&#125;&lt;/g1.max.size.percent&gt; &lt;jvm.Xms&gt;$&#123;prod.jvm.Xms&#125;&lt;/jvm.Xms&gt; &lt;jvm.Xmx&gt;$&#123;prod.jvm.Xmx&#125;&lt;/jvm.Xmx&gt; &lt;pushImage&gt;true&lt;/pushImage&gt; &lt;spring.profile&gt;prod&lt;/spring.profile&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!--prod的默认激活git插件方便使用tag做为版本号--&gt; &lt;plugin&gt; &lt;groupId&gt;pl.project13.maven&lt;/groupId&gt; &lt;artifactId&gt;git-commit-id-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/profile&gt;&lt;profile&gt; &lt;!--test的profile--&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;base.docker.repository&gt;$&#123;test.docker.repository&#125;&lt;/base.docker.repository&gt; &lt;eureka.url&gt;$&#123;test.eureka&#125;&lt;/eureka.url&gt; &lt;g1.new.size.percent&gt;40&lt;/g1.new.size.percent&gt; &lt;g1.max.size.percent&gt;70&lt;/g1.max.size.percent&gt; &lt;jvm.Xms&gt;$&#123;test.jvm.Xms&#125;&lt;/jvm.Xms&gt; &lt;jvm.Xmx&gt;$&#123;test.jvm.Xmx&#125;&lt;/jvm.Xmx&gt; &lt;pushImage&gt;false&lt;/pushImage&gt; &lt;!--test环境直接指定dockerimage说的版本号为latest--&gt; &lt;git.commit.id.describe-short&gt;latest&lt;/git.commit.id.describe-short&gt; &lt;spring.profile&gt;test&lt;/spring.profile&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/profile&gt;&lt;/profiles&gt; 构建 打包prod版本的 1mvn clean pacakge -Pprod 打包test版本的 1mvn clean pacakge -Ptest 打包个性化的版本的 1mvn clean pacakge -Djvm.Xms=8G -Djvm.Xmx=8G -Pdocker 检验 如果你配置正确，你将会看到如下输出，如果你还开启的push，那么将看到push的日志 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869[INFO] --- docker-maven-plugin:1.2.0:build (default) @ user-server ---[INFO] Using authentication suppliers: [ConfigFileRegistryAuthSupplier, FixedRegistryAuthSupplier][INFO] Copying /Users/freeman/IdeaProjects2/user-server/target/user-server.jar -&gt; /Users/freeman/IdeaProjects2/user-server/target/docker/user-server.jar[INFO] Building image hub.mayixiaoke.com/my/user-server:latestStep 1/12 : FROM freemanliu/openjre:1.8.0_171_font ---&gt; 753ecb9267d1Step 2/12 : ENV CI_COMPILER_COUNT 8 ---&gt; Using cache ---&gt; 93bebb3621d4Step 3/12 : ENV EUREKA_SERVER \"-DEUREKA_SERVER=http://192.168.0.204:8761/eureka/\" ---&gt; Running in 42d31fcd4a7dRemoving intermediate container 42d31fcd4a7d ---&gt; c1e478140e99Step 4/12 : ENV G1_MAX_NEW_SIZE_PERCENT 70 ---&gt; Running in 794778b524dcRemoving intermediate container 794778b524dc ---&gt; 6cf5ff851174Step 5/12 : ENV G1_NEW_SIZE_PERCENT 40 ---&gt; Running in 85592d62fe30Removing intermediate container 85592d62fe30 ---&gt; 8b69e9c6371eStep 6/12 : ENV JAVA_HEAP_XMS 450m ---&gt; Running in 683b34295fecRemoving intermediate container 683b34295fec ---&gt; 24917bf053e6Step 7/12 : ENV JAVA_HEAP_XMX 2G ---&gt; Running in 74ba3caadd4bRemoving intermediate container 74ba3caadd4b ---&gt; d1bd5ba01b7dStep 8/12 : ENV JAVA_OPTS -Dservice.name=user-server -XX:+UnlockExperimentalVMOptions -Xms$&#123;JAVA_HEAP_XMS&#125; -Xmx$&#123;JAVA_HEAP_XMX&#125; -XX:CICompilerCount=$&#123;CI_COMPILER_COUNT&#125; -XX:G1NewSizePercent=$&#123;G1_NEW_SIZE_PERCENT&#125; -XX:G1MaxNewSizePercent=$&#123;G1_MAX_NEW_SIZE_PERCENT&#125; -DEUREKA_SERVER=$&#123;EUREKA_SERVER&#125; -Dspring.profiles.active=test -Dspring.cloud.config.profile=test -XX:+UseG1GC -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -XX:+UseStringDeduplication -XX:+UseCompressedOops -XX:+OptimizeStringConcat ---&gt; Running in 2b4e73c01ad7Removing intermediate container 2b4e73c01ad7 ---&gt; 2fd9b3ffa0adStep 9/12 : ENV TZ Asia/Shanghai ---&gt; Running in 85946bd9bb3cRemoving intermediate container 85946bd9bb3c ---&gt; b588ab3d7e2cStep 10/12 : WORKDIR /work ---&gt; Running in a41a0545883fRemoving intermediate container a41a0545883f ---&gt; 53c863bbcdbfStep 11/12 : ADD user-server.jar . ---&gt; a3cf23754886Step 12/12 : CMD /sbin/tini java $&#123;JAVA_OPTS&#125; -jar user-server.jar ---&gt; Running in c3a716574080Removing intermediate container c3a716574080 ---&gt; 262898825ee2ProgressMessage&#123;id=null, status=null, stream=null, error=null, progress=null, progressDetail=null&#125;Successfully built 262898825ee2Successfully tagged hub.xxxx.com/my/user-server:latest[INFO] Built hub.xxxx.com/my/user-server:latest[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 26.332 s[INFO] Finished at:[INFO] ------------------------------------------------------------------------ 如果你使用的cmd命令跟我一样，那么你还可以执行sh终端，查看我们的环境变量 123docker run -it --rm hub.xxx.com/my/user-server:latest shecho $JAVA_OPTS-Dservice.name=user-server -XX:+UnlockExperimentalVMOptions -Xms450M -Xmx2G -XX:CICompilerCount=8 -XX:G1NewSizePercent=5 -XX:G1MaxNewSizePercent=60 -DEUREKA_SERVER=-DEUREKA_SERVER=http://192.168.0.204:8761/eureka/ -Dspring.profiles.active=prod -Dspring.cloud.config.profile=prod -XX:+UseG1GC -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -XX:+UseStringDeduplication -XX:+UseCompressedOops -XX:+OptimizeStringConcat 如果你感兴趣还可以这样 123docker run -it --rm -e JAVA_HEAP_XMS=8G -e JAVA_HEAP_XMX=8G hub.xxx.com/my/user-server:latest shecho $JAVA_OPTS-Dservice.name=user-server -XX:+UnlockExperimentalVMOptions -Xms4G -Xmx4G -XX:CICompilerCount=8 -XX:G1NewSizePercent=5 -XX:G1MaxNewSizePercent=60 -DEUREKA_SERVER=-DEUREKA_SERVER=http://192.168.0.204:8761/eureka/ -Dspring.profiles.active=prod -Dspring.cloud.config.profile=prod -XX:+UseG1GC -XX:+AggressiveOpts -XX:+UseFastAccessorMethods -XX:+UseStringDeduplication -XX:+UseCompressedOops -XX:+OptimizeStringConcat 思考：同理我们想要灵活的修改其他参数是不是一个流程呢？比如我要修改G1的G1NewSizePercent和G1MaxNewSizePercent。有几种方式呢？你觉得那种方式更优雅呢？","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://qingmu.io/tags/微服务/"},{"name":"docker","slug":"docker","permalink":"https://qingmu.io/tags/docker/"}]},{"title":"扩展spring-cloud-ribbon支持灰度","slug":"Extended-spring-cloud-ribbon-supports-grayscale","date":"2018-08-07T04:42:47.000Z","updated":"2018-11-15T09:32:31.207Z","comments":true,"path":"2018/08/07/Extended-spring-cloud-ribbon-supports-grayscale/","link":"","permalink":"https://qingmu.io/2018/08/07/Extended-spring-cloud-ribbon-supports-grayscale/","excerpt":"目标 扩展ribbon完成灰度调用 完成对zuul的支持 完成服务间调用的支持 实战，解决在开发环境，进行开发中的测试,DEBUG.在微服务的模式下,需要在开发者的机器启动大量服务，启动大量的服务需要大量的内存和大量的时间，在我们时间的项目开发中，在16G的机器上甚至无法进行调和测试相关工作。","text":"目标 扩展ribbon完成灰度调用 完成对zuul的支持 完成服务间调用的支持 实战，解决在开发环境，进行开发中的测试,DEBUG.在微服务的模式下,需要在开发者的机器启动大量服务，启动大量的服务需要大量的内存和大量的时间，在我们时间的项目开发中，在16G的机器上甚至无法进行调和测试相关工作。 思路 ZUUL调用服务 利用eureka的mate-map机制，在服务启动时添加部分元数据信息 1eureka.instance.metadata-map.developer=qingmu 在访问zuul网关时携带参数developer=qingmu 对zuul Filter 进行扩展,获取到参数中的developer,并设置到threadlocal中 对ribbon进行扩展，重写ZoneAvoidanceRule.choose 方法，返回server之前获取到ThreadLocal中预先设置的developer，并获取到allServers,遍历allServers,获取到server的的metadata-map判断其中是否有developer=qingmu 如果有则命中,添加进一个新集合，遍历完成之后产生新的集合，使用的新的集合完成server选择。如未能命中，则走已有的默认实现。如此便完成了ZUUL对server的灰度调用。 服务调用服务 同样利用eureka的机制 同理zuul会将developer进行传递 当传递到服务时，服务自定义一个拦截器，将参数developer 取出，存入自己的ThreadLocal中，方便后续的feign使用 当服务进行服务调用时 首先我们对feign的拦截器进行扩展，将developer 参数继续传递下去，方便接下来的服务老铁继续使用 其次走对ribbon扩展的相关逻辑。即完成了服务直接的灰度调用 注意 由于使用了threadlocal 变量进行参数隐式传递，Hystrix的ThreadLocal隔离模式是无法使用了。 由于jdk提供的线程池实现，无法进行跨线程池的threadlocal变量传递 所以在进行灰度调用时，可使用信号量隔离模式 设置strategy为SEMAPHORE 12hystrix.command.default.execution.isolation.strategy: SEMAPHORE 也可以使用自定义策略的当时进行threadlocal的传递 继承HystrixConcurrencyStrategy策略类覆写wrapCallable方法即可 RibbonHystrixConcurrencyStrategy.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899@Slf4jpublic class RibbonHystrixConcurrencyStrategy extends HystrixConcurrencyStrategy &#123; private HystrixConcurrencyStrategy delegate; public RibbonHystrixConcurrencyStrategy() &#123; try &#123; this.delegate = HystrixPlugins.getInstance().getConcurrencyStrategy(); if (this.delegate instanceof RibbonHystrixConcurrencyStrategy) &#123; // Welcome to singleton hell... return; &#125; HystrixCommandExecutionHook commandExecutionHook = HystrixPlugins .getInstance().getCommandExecutionHook(); HystrixEventNotifier eventNotifier = HystrixPlugins.getInstance() .getEventNotifier(); HystrixMetricsPublisher metricsPublisher = HystrixPlugins.getInstance() .getMetricsPublisher(); HystrixPropertiesStrategy propertiesStrategy = HystrixPlugins.getInstance() .getPropertiesStrategy(); this.logCurrentStateOfHystrixPlugins(eventNotifier, metricsPublisher, propertiesStrategy); HystrixPlugins.reset(); HystrixPlugins.getInstance().registerConcurrencyStrategy(this); HystrixPlugins.getInstance() .registerCommandExecutionHook(commandExecutionHook); HystrixPlugins.getInstance().registerEventNotifier(eventNotifier); HystrixPlugins.getInstance().registerMetricsPublisher(metricsPublisher); HystrixPlugins.getInstance().registerPropertiesStrategy(propertiesStrategy); &#125; catch (Exception e) &#123; log.error(\"Failed to register Sleuth Hystrix Concurrency Strategy\", e); &#125; &#125; private void logCurrentStateOfHystrixPlugins(HystrixEventNotifier eventNotifier, HystrixMetricsPublisher metricsPublisher, HystrixPropertiesStrategy propertiesStrategy) &#123; if (log.isDebugEnabled()) &#123; log.debug(\"Current Hystrix plugins configuration is [\" + \"concurrencyStrategy [\" + this.delegate + \"],\" + \"eventNotifier [\" + eventNotifier + \"],\" + \"metricPublisher [\" + metricsPublisher + \"],\" + \"propertiesStrategy [\" + propertiesStrategy + \"],\" + \"]\"); log.debug(\"Registering Sleuth Hystrix Concurrency Strategy.\"); &#125; &#125; @Override public &lt;T&gt; Callable&lt;T&gt; wrapCallable(Callable&lt;T&gt; callable) &#123; return new WrappedCallable&lt;&gt;(callable, RibbonFilterContextHolder.getCurrentContext()); &#125; @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixProperty&lt;Integer&gt; corePoolSize, HystrixProperty&lt;Integer&gt; maximumPoolSize, HystrixProperty&lt;Integer&gt; keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; return this.delegate.getThreadPool(threadPoolKey, corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); &#125; @Override public ThreadPoolExecutor getThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolProperties threadPoolProperties) &#123; return this.delegate.getThreadPool(threadPoolKey, threadPoolProperties); &#125; @Override public BlockingQueue&lt;Runnable&gt; getBlockingQueue(int maxQueueSize) &#123; return this.delegate.getBlockingQueue(maxQueueSize); &#125; @Override public &lt;T&gt; HystrixRequestVariable&lt;T&gt; getRequestVariable( HystrixRequestVariableLifecycle&lt;T&gt; rv) &#123; return this.delegate.getRequestVariable(rv); &#125; public static class WrappedCallable&lt;T&gt; implements Callable&lt;T&gt; &#123; private final Callable&lt;T&gt; target; private final RibbonFilterContext ribbonFilterContext; public WrappedCallable(Callable&lt;T&gt; target, RibbonFilterContext ribbonFilterContext) &#123; this.target = target; this.ribbonFilterContext = ribbonFilterContext; &#125; @Override public T call() throws Exception &#123; try &#123; RibbonFilterContextHolder.setCurrentContext(ribbonFilterContext); return target.call(); &#125; finally &#123; RibbonFilterContextHolder.clearCurrentContext(); &#125; &#125; &#125;&#125; 代码实现zuul 拦截器扩展1234567891011121314151617181920212223242526272829303132333435// RibbonFilter.java@Componentpublic class RibbonFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FORM_BODY_WRAPPER_FILTER_ORDER; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RibbonFilterContextHolder.clearCurrentContext(); RequestContext ctx = RequestContext.getCurrentContext(); final HttpServletRequest request = ctx.getRequest(); final String requestURI = request.getRequestURI(); if (request.getParameter(\"developer\") != null) &#123; // put the serviceId in `RequestContext` RibbonFilterContextHolder.getCurrentContext() .add(\"developer\", request.getParameter(\"developer\")); &#125; else if (request.getHeader(\"developer\") != null) &#123; RibbonFilterContextHolder.getCurrentContext() .add(\"developer\", request.getHeader(\"developer\")); &#125; return true; &#125; MetadataAwareRule ribbon 规则覆写123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class MetadataAwareRule extends ZoneAvoidanceRule &#123; @Override public Server choose(Object key) &#123; final RibbonFilterContext context = RibbonFilterContextHolder.getCurrentContext(); ILoadBalancer lb = getLoadBalancer(); final List&lt;Server&gt; allServers = lb.getAllServers(); // 存放已打标签但不满足标签的server final List&lt;Server&gt; metaServers = new ArrayList&lt;&gt;(); // 存放未标签的server final List&lt;Server&gt; noMetaServers = new ArrayList&lt;&gt;(); // 匹配成功的server final List&lt;Server&gt; matchedMetaServers = new ArrayList&lt;&gt;(); final Map&lt;String, String&gt; attributes = context.getAttributes(); // 取得接口端传入的参数 final String inputDeveloper = attributes.get(\"developer\"); for (Server server : allServers) &#123; if (server instanceof DiscoveryEnabledServer) &#123; final DiscoveryEnabledServer discoveryEnabledServer = (DiscoveryEnabledServer) server; final Map&lt;String, String&gt; metadata = discoveryEnabledServer.getInstanceInfo().getMetadata(); final String developer = metadata.get(\"developer\"); // 如果没有meta数据 表示是测试服务上的地址 if (developer == null || developer.equals(\"\")) &#123; // 存放并没有打标签的server noMetaServers.add(server); &#125; else &#123; // 如果匹配成功开发者直接调用 if (inputDeveloper != null &amp;&amp; (!\"\".equals(inputDeveloper)) &amp;&amp; developer.equals(inputDeveloper)) &#123; matchedMetaServers.add(server); &#125; else &#123; // 存入server有标签但是不匹配的server metaServers.add(server); &#125; &#125; &#125; &#125; //优先走自定义路由。即满足灰度要求的server if (!matchedMetaServers.isEmpty()) &#123; com.google.common.base.Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(matchedMetaServers, key); if (server.isPresent()) &#123; return server.get(); &#125; else &#123; return null; &#125; &#125; // 如果没有匹配成功的则走 else &#123; if (!noMetaServers.isEmpty()) &#123; com.google.common.base.Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(noMetaServers, key); if (server.isPresent()) &#123; return server.get(); &#125; else &#123; return null; &#125; &#125; else &#123; // 似情况打开 return null;// com.google.common.base.Optional&lt;Server&gt; server = getPredicate().chooseRoundRobinAfterFiltering(metaServers, key);// if (server.isPresent()) &#123;// return server.get();// &#125; else &#123;// return null;// &#125; &#125; &#125; &#125;&#125; ThreadLocal 变量封装12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Setter@Getterpublic class RibbonFilterContext &#123; private final Map&lt;String, String&gt; attributes = new HashMap&lt;&gt;(); public RibbonFilterContext add(String key, String value) &#123; attributes.put(key, value); return this; &#125; public String get(String key) &#123; return attributes.get(key); &#125; public RibbonFilterContext remove(String key) &#123; attributes.remove(key); return this; &#125; public Map&lt;String, String&gt; getAttributes() &#123; return Collections.unmodifiableMap(attributes); &#125;&#125;public class RibbonFilterContextHolder &#123; private static final ThreadLocal&lt;RibbonFilterContext&gt; contextHolder = new InheritableThreadLocal&lt;RibbonFilterContext&gt;() &#123; @Override protected RibbonFilterContext initialValue() &#123; return new RibbonFilterContext(); &#125; &#125;; public static RibbonFilterContext getCurrentContext() &#123; return contextHolder.get(); &#125; public static void setCurrentContext(RibbonFilterContext context) &#123; contextHolder.set(context); &#125; public static void clearCurrentContext() &#123; contextHolder.remove(); &#125;&#125; 激活自定义Rule1234567891011121314151617181920212223@Configuration@ConditionalOnClass(DiscoveryEnabledNIWSServerList.class)@AutoConfigureBefore(RibbonClientConfiguration.class)public class RibbonMetaFilterAutoConfiguration &#123; @Bean @ConditionalOnMissingBean @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public MetadataAwareRule metadataAwareRule() &#123; return new MetadataAwareRule(); &#125; /** * 根据自己的选择判断时候激活改策略 * @return */ @Bean public RibbonHystrixConcurrencyStrategy ribbonHystrixConcurrencyStrategy()&#123; return new RibbonHystrixConcurrencyStrategy(); &#125;&#125; 对Feign进行扩展将developer进行传递123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration@EnableWebMvcpublic class MyAutoConfigurationBefore extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new HandlerInterceptor() &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (request.getParameter(\"developer\") != null) &#123; RibbonFilterContextHolder.getCurrentContext() .add(\"developer\", request.getParameter(\"developer\")); &#125; else if (request.getHeader(\"developer\") != null) &#123; RibbonFilterContextHolder.getCurrentContext() .add(\"developer\", request.getHeader(\"developer\")); &#125; return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; RibbonFilterContextHolder.clearCurrentContext(); &#125; &#125;); &#125;&#125; /** * @see feign.RequestInterceptor * @return */ @Bean public RequestInterceptor headerInterceptor() &#123; return requestTemplate -&gt; &#123; final String developer = RibbonFilterContextHolder.getCurrentContext().get(\"developer\"); if (StringUtils.isNotBlank(developer)) &#123; requestTemplate.header(\"developer\", developer); &#125; &#125;; &#125; 如此便完成了灰度调用 简单的说就是利用了threadlocal机制存储了从前端调用者传入的特殊参数 在进行调用之前，拦截下负载均衡的choose方法，在调用之前对从注册中心获取到的所有server进行匹配 成功则走匹配成功的server，匹配无一个成功的就走默认方法即可。","categories":[],"tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"https://qingmu.io/tags/spring-cloud/"},{"name":"ribbon","slug":"ribbon","permalink":"https://qingmu.io/tags/ribbon/"},{"name":"zuul","slug":"zuul","permalink":"https://qingmu.io/tags/zuul/"},{"name":"微服务","slug":"微服务","permalink":"https://qingmu.io/tags/微服务/"}]},{"title":"kubernetes全自动弹性伸缩组件","slug":"kubernetes-metrics-server","date":"2018-08-02T04:02:42.000Z","updated":"2018-08-14T07:17:55.070Z","comments":true,"path":"2018/08/02/kubernetes-metrics-server/","link":"","permalink":"https://qingmu.io/2018/08/02/kubernetes-metrics-server/","excerpt":"目标 使用容器完成 metrics-server 部署 演示 Horizontal Pod Autoscaling （pod 自动缩放） 部署 metrics-server 服务 Horizontal Pod Autoscaler（HPA）控制器用于实现基于CPU使用率进行自动Pod伸缩的功能。 HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义是时长（默认30秒），周期性监控目标Pod的CPU使用率，并在满足条件时对ReplicationController或Deployment中的Pod副本数进行调整，以符合用户定义的平均Pod CPU使用率。 在新版本的kubernetes中 Pod CPU使用率不在来源于heapster，而是来自于metrics-server 官网原话是 The --horizontal-pod-autoscaler-use-rest-clients is true or unset. Setting this to false switches to Heapster-based autoscaling, which is deprecated.","text":"目标 使用容器完成 metrics-server 部署 演示 Horizontal Pod Autoscaling （pod 自动缩放） 部署 metrics-server 服务 Horizontal Pod Autoscaler（HPA）控制器用于实现基于CPU使用率进行自动Pod伸缩的功能。 HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义是时长（默认30秒），周期性监控目标Pod的CPU使用率，并在满足条件时对ReplicationController或Deployment中的Pod副本数进行调整，以符合用户定义的平均Pod CPU使用率。 在新版本的kubernetes中 Pod CPU使用率不在来源于heapster，而是来自于metrics-server 官网原话是 The --horizontal-pod-autoscaler-use-rest-clients is true or unset. Setting this to false switches to Heapster-based autoscaling, which is deprecated. yml 文件来自于github https://github.com/kubernetes-incubator/metrics-server/tree/master/deploy/1.8+ /etc/kubernetes/pki/front-proxy-ca.pem 文件来自于部署kubernetes集群 需要对yml文件进行修改才可使用 改动如下 利用Flags-horizontal-pod-autoscaler-sync-period确定hPa对于Pods组指标的监控频率。默认的周期为30秒。 两次扩展操作之间的默认间隔为3分钟，可以Flags来控制-horizontal-pod-autoscaler-upscale-delay 两个缩小操作之间的默认间隔为5分钟，同样可以通过Flags来控制-horizontal-pod-autoscaler-downscale-delay 1234567891011121314151617- name: metrics-server image: freemanliu/metrics-server-amd64:v0.2.1 # gcr 被墙了替换镜像 imagePullPolicy: Always volumeMounts: - mountPath: /etc/kubernetes/pki name: ca-ssl command: - /metrics-server - --source=kubernetes.summary_api:'' - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem - --requestheader-username-headers=X-Remote-User - --requestheader-group-headers=X-Remote-Group - --requestheader-extra-headers-prefix=X-Remote-Extra-volumes:- name: ca-ssl hostPath: path: /etc/kubernetes/pki 这里将github提供的多个文件合并为一个方便一些 kubectl apply -f metrics-server.yml 进行部署 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138# metrics-server.yml---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: metrics-server:system:auth-delegatorroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:auth-delegatorsubjects:- kind: ServiceAccount name: metrics-server namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: metrics-server-auth-reader namespace: kube-systemroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: extension-apiserver-authentication-readersubjects:- kind: ServiceAccount name: metrics-server namespace: kube-system---apiVersion: apiregistration.k8s.io/v1beta1kind: APIServicemetadata: name: v1beta1.metrics.k8s.iospec: service: name: metrics-server namespace: kube-system group: metrics.k8s.io version: v1beta1 insecureSkipTLSVerify: true groupPriorityMinimum: 100 versionPriority: 100---apiVersion: v1kind: ServiceAccountmetadata: name: metrics-server namespace: kube-system---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: metrics-server namespace: kube-system labels: k8s-app: metrics-serverspec: selector: matchLabels: k8s-app: metrics-server template: metadata: name: metrics-server labels: k8s-app: metrics-server spec: serviceAccountName: metrics-server containers: - name: metrics-server image: freemanliu/google_containers-metrics-server-amd64:v0.2.1 imagePullPolicy: Always volumeMounts: - mountPath: /etc/kubernetes/pki name: ca-ssl command: - /metrics-server - --source=kubernetes.summary_api:'' - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem - --requestheader-username-headers=X-Remote-User - --requestheader-group-headers=X-Remote-Group - --requestheader-extra-headers-prefix=X-Remote-Extra- volumes: - name: ca-ssl hostPath: path: /etc/kubernetes/pki---apiVersion: v1kind: Servicemetadata: name: metrics-server namespace: kube-system labels: kubernetes.io/name: \"Metrics-server\"spec: selector: k8s-app: metrics-server ports: - port: 443 protocol: TCP targetPort: 443---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: system:metrics-serverrules:- apiGroups: - \"\" resources: - pods - nodes - nodes/stats - namespaces verbs: - get - list - watch- apiGroups: - \"extensions\" resources: - deployments verbs: - get - list - watch---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: system:metrics-serverroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:metrics-serversubjects:- kind: ServiceAccount name: metrics-server namespace: kube-system 测试metrics-server 是否部署成功 1234567891011kubectl get --raw /apis/metrics.k8s.io/v1beta1&#123;\"kind\":\"APIResourceList\",\"apiVersion\":\"v1\",\"groupVersion\":\"metrics.k8s.io/v1beta1\",\"resources\":[&#123;\"name\":\"nodes\",\"singularName\":\"\",\"namespaced\":false,\"kind\":\"NodeMetrics\",\"verbs\":[\"get\",\"list\"]&#125;,&#123;\"name\":\"pods\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"PodMetrics\",\"verbs\":[\"get\",\"list\"]&#125;]&#125;[root@k8s-m1 ~]# kubectl top nodeNAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-m1 113m 2% 1080Mi 14% k8s-m2 133m 3% 1086Mi 14% k8s-m3 100m 2% 1029Mi 13% k8s-n1 146m 3% 403Mi 5% k8s-n2 50m 1% 387Mi 5% k8s-n3 38m 0% 284Mi 3% 部署HPA实验案列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 创建 pod 和 service[root@k8s-m1 ~]# kubectl run php-apache --image=freemanliu/hpa-example --requests=cpu=200m --expose --port=80service \"php-apache\" createddeployment \"php-apache\" created# 创建 autoscaler[root@k8s-m1 ~]# kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10deployment \"php-apache\" autoscaled# 查看HPA [root@k8s-m1 ~]# kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 0%/50% 1 10 1 2h[root@k8s-m1 ~]# kubectl describe hpaName: php-apacheNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;CreationTimestamp: Thu, 02 Aug 2018 11:37:26 +0800Reference: Deployment/php-apacheMetrics: ( current / target ) resource cpu on pods (as a percentage of request): 45% (90m) / 50%Min replicas: 1Max replicas: 10Deployment pods: 1 current / 1 desiredConditions: Type Status Reason Message ---- ------ ------ ------- AbleToScale True ReadyForNewScale the last scale time was sufficiently old as to warrant a new scale ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from cpu resource utilization (percentage of request) # 增加负载[root@k8s-m1 ~]# kubectl run -i --tty load-generator --image=busybox /bin/sh while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done # 过一会儿在查看 hpa 可以看到CPU负载升高了[root@k8s-m1 ~]# kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 387%/50% 1 10 1 2h# 在等30s左右 在查看HPA 可以发现已经进行自动扩容了[root@k8s-m1 ~]# kubectl get hpaNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEphp-apache Deployment/php-apache 270%/50% 1 10 4 2h# 查看depoment 已经扩展到了4个了[root@k8s-m1 ~]# kubectl get deployment php-apacheNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEphp-apache 4 4 4 4 2h# 此时停止掉循环 过一会儿会发现 php-apache pod 数量又降下来了 自动缩减了pod数量# 清理 php-apachekubectl delete deployment/php-apachekubectl delete service/php-apachkubectl delete hpa php-apache 参考资料 https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ https://kubernetes.feisky.xyz/zh/concepts/autoscaling.html http://blog.51cto.com/ylw6006/2114338","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://qingmu.io/tags/kubernetes/"},{"name":"hpa","slug":"hpa","permalink":"https://qingmu.io/tags/hpa/"},{"name":"metrics-server","slug":"metrics-server","permalink":"https://qingmu.io/tags/metrics-server/"}]},{"title":"Kubernetes-v1.11.1-全自动ansible部署指南","slug":"Kubernetes-v1-11-1-ansible","date":"2018-07-31T10:24:23.000Z","updated":"2018-08-13T09:35:16.351Z","comments":true,"path":"2018/07/31/Kubernetes-v1-11-1-ansible/","link":"","permalink":"https://qingmu.io/2018/07/31/Kubernetes-v1-11-1-ansible/","excerpt":"目标 部署3节点的HA Master(v1.11.1目前最新版)+3个worker node 节点 整个集群使用static pod方式启动包括 使用ipvs替代iptables,实现svc网络 容器部署flannel插件，coredns插件等相关插件","text":"目标 部署3节点的HA Master(v1.11.1目前最新版)+3个worker node 节点 整个集群使用static pod方式启动包括 使用ipvs替代iptables,实现svc网络 容器部署flannel插件，coredns插件等相关插件 镜像 由于gcr的镜像被墙住了所以这里使用我们自己同步到dockerhub的镜像 我们使用github结合dockerhub自动构建的放松进行镜像的自动同步管理 镜像全部使用freemanliu下同步过来的镜像（https://hub.docker.com/r/freemanliu/ ） 镜像Dockerfile 托管在 https://github.com/goudai/kubernetes-images 大概需要用到到的镜像如下 12345678910REPOSITORY TAG IMAGE ID CREATED SIZEzhangguanzhang/keepalived 1.3.9 7d0a6d093f78 9 days ago 14MBfreemanliu/kube-proxy-amd64 v1.11.1 d5c25579d0ff 2 weeks ago 97.8MBfreemanliu/kube-scheduler-amd64 v1.11.1 272b3a60cd68 2 weeks ago 56.8MBfreemanliu/kube-controller-manager-amd64 v1.11.1 52096ee87d0e 2 weeks ago 155MBfreemanliu/kube-apiserver-amd64 v1.11.1 816332bd9d11 2 weeks ago 187MBfreemanliu/etcd-amd64 3.2.18 b8df3b177be2 3 months ago 219MBfreemanliu/flannel v0.10.0-amd64 f0fad859c909 6 months ago 44.6MBfreemanliu/pause-amd64 3.1 da86e6ba6ca1 7 months ago 742kBkairen/haproxy 1.7 733c4b4d75c4 14 months ago 14.7MB 使用软件版本 软件名称 版本 os centos 7.x etcd v3.2.18 keepalived 1.3.9 flannel v0.10.0-amd64 haproxy 1.7 kubernetes v1.11.1(master=&gt;(kube-apiserver,kube-controller-manager,kube-scheduler)) ipvsadm v1.27 主机布局 请按照如下格式修改主机名 1vim /etc/hostname hostname ip soft k8s-m1 192.168.0.101 haproxy,etcd,kubernetes,flannel k8s-m2 192.168.0.102 haproxy,etcd,kubernetes,flannel k8s-m3 192.168.0.103 haproxy,etcd,kubernetes,flannel k8s-n1 192.168.0.104 kube-proxy,flannel k8s-n2 192.168.0.105 kube-proxy,flannel k8s-n2 192.168.0.106 kube-proxy,flannel 新增hosts 12345678echo '192.168.0.101 k8s-m1192.168.0.102 k8s-m2192.168.0.103 k8s-m3192.168.0.104 k8s-n1192.168.0.105 k8s-n2192.168.0.106 k8s-n3' &gt;&gt; /etc/hosts 环境准备(以下操作请在每一台主机执行，请确保使用root用户) 可在一台主机完成以下操作后制作相关镜像，使用镜像分发 linux环境设置 配置阿里云yum源 123456#备份mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup# 添加阿里云repowget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo#生成缓存yum makecache 安装ipvsadm,wget ,socat 1yum -y install ipvsadm wget socat 加载内核ipvs模块 1234567891011cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashipvs_modules=\"ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed nf_conntrack_ipv4\"for kernel_module in \\$&#123;ipvs_modules&#125;; do /sbin/modinfo -F filename \\$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1 if [ \\$? -eq 0 ]; then /sbin/modprobe \\$&#123;kernel_module&#125; fidoneEOFchmod +x /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs 正确加载之后输出如下 1234567891011121314nf_nat 26787 3 ip_vs_ftp,nf_nat_ipv4,nf_nat_masquerade_ipv4ip_vs_sed 12519 0ip_vs_nq 12516 0ip_vs_sh 12688 0ip_vs_dh 12688 0ip_vs_lblcr 12922 0ip_vs_lblc 12819 0ip_vs_wrr 12697 0ip_vs_rr 12600 9ip_vs_wlc 12519 0ip_vs_lc 12516 0ip_vs 141473 31 ip_vs_dh,ip_vs_lc,ip_vs_nq,ip_vs_rr,ip_vs_sh,ip_vs_ftp,ip_vs_sed,ip_vs_wlc,ip_vs_wrr,ip_vs_lblcr,ip_vs_lblcnf_conntrack 133053 7 ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack_ipv4libcrc32c 12644 4 xfs,ip_vs,nf_nat,nf_conntrack 关闭防火墙，设置内核参数，关闭swap 1234567891011121314151617181920212223echo 'net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1vm.swappiness = 0net.ipv4.neigh.default.gc_stale_time = 120net.ipv4.conf.all.rp_filter = 0net.ipv4.conf.default.rp_filter = 0net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_announce = 2net.ipv4.ip_forward = 1net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 1024net.ipv4.tcp_synack_retries = 2net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-arptables = 1fs.may_detach_mounts = 1' &gt; /etc/sysctl.conf&amp;&amp; swapoff -a&amp;&amp; sysctl -w vm.swappiness=0&amp;&amp; sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab&amp;&amp; systemctl disable --now firewalld 关闭selinux 1234# 将SELINUX=enforcing改为SELINUX=disabledvim /etc/selinux/config# 确保 getenforce 命令输出 Disabledgetenforce 确保如下输出为1 12cat /proc/sys/net/ipv4/ip_forward1 docker 安装12345678910111213141516171819202122# step 1: 安装必要的一些系统工具sudo yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Step 3: 更新并安装 Docker-CEsudo yum makecache fastsudo yum -y install docker-ce# Step 4: 开启Docker服务systemctl start docker# 开启开机自启systemctl enable docker# 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# yum list docker-ce.x86_64 --showduplicates | sort -r# Loading mirror speeds from cached hostfile# Loaded plugins: branch, fastestmirror, langpacks# docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable# docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable# docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# Available Packages# Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos)# sudo yum -y install docker-ce-[VERSION] 设置docker加速镜像 这里使用阿里云提供的镜像服务，需自己去注册后替换 阿里云镜像帮助指南 123456mkdir -p /etc/docker/echo '&#123;\"registry-mirrors\": [\"https://xxxx.mirror.aliyuncs.com\"]&#125;' &gt; /etc/docker/daemon.json 完成操作之后请reboot 重启host 一下操作任选一台MASTER节点操作即可（这里选择k8s-m1） 安装必须软件 1yum -y install ansible git 下载kubernetes（主要使用到kubelet和kuberctl） 12345678# 在~目录操作cd ~/# 自备梯子wget https://storage.googleapis.com/kubernetes-release/release/v1.11.1/kubernetes-node-linux-amd64.tar.gz# 无梯子 国内七牛云CDNwget http://ols7lqkih.bkt.clouddn.com/kubernetes-node-linux-amd64-v1.11.1.tar.gz#无梯子 百度云盘链接: https://pan.baidu.com/s/1kbz1X_MH3XIjIXiG80tBmA 密码: rk4j clone ansible 脚本项目 123456cd ~/git clone https://github.com/goudai/ansible-kubernetes-v1.11.1-ipvs.git# 解压缩 kubernetestar xf kubernetes-node-linux-amd64.tar.gz# copy 需要的文件到ansbile 的分发目录中,这两个文件会被分发到集群中所有机器cp kubernetes/node/bin/&#123;kubectl,kubelet&#125; ansible-kubernetes-v1.11.1-ipvs/roles/scp/files 修改hosts文件 1234567891011121314#切换到项目目录cd ~/ansible-kubernetes-v1.11.1-ipvs#修改hosts 文件 vim hosts#把文件中一下ip替换为自己的ip[otherMaster] #替换为你的k8s-m2,k8s-m3的ip192.168.0.102 192.168.0.103# 如果每个每个机器的密码不一致，请使用如下格式# 并注释 group_vars/all.yml 中的 ansible_ssh_pass: 111111 这一行# 192.168.0.102 ansible_ssh_pass=password1 ansible_ssh_port=22# 192.168.0.103 ansible_ssh_pass=password2 ansible_ssh_port=22[Node] # 替换为你的k8s-n1 的ip192.168.0.104 修改全局变量参数group_vars/all.yml 1234567891011cd ~/ansible-kubernetes-v1.11.1-ipvsvim group_vars/all.yml# TOKEN相关信息可以不用修改 如想修改可以用如下方式重新生成# TOKEN可以使用head -c 32 /dev/urandom | base64生成替换# TOKEN_ID可以使用openssl rand 3 -hex生成# TOKEN_SECRET使用openssl rand 8 -hex# VIP 和 NETMASK 修改# 这里的VIP 是keepalived 所要使用的 VIP ，修改为你所在网段的未使用的IP即可 # NETMASK 为VIP的掩码# INTERFACE_NAME 为让vip绑定的网卡 其余相关参数如果特殊要求可不更改 开始自动化部署 分发 /etc/hosts 文件 12# 主要保证master机器上都有上面修改的hosts信息 ansible all -m copy -a \"src=/etc/hosts dest=/etc/hosts\" 分发kubectl,kubelet,cfssl,cni 1ansible-playbook distribute-file.yml 生成 etcd 和 kubernetes 所需要证书并分发到所有节点 12cd ~/ansible-kubernetes-v1.11.1-ipvsansible-playbook gen-etcd-ca-kubenetes-ca.yml 部署master kubelet systemd 方式部署 并启动 12cd ~/ansible-kubernetes-v1.11.1-ipvsansible-playbook deploy-master.yml 部署执行完成之后 请等待kubernetes集群 启动完成 可通过tail -f /var/log/messages 查看kubelet相关日志输出 正确启动成功之后的输出如下 12345678910111213141516171819202122232425262728293031323334353637[root@k8s-m1 kubernetes]# kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-2 Healthy &#123;\"health\": \"true\"&#125; etcd-0 Healthy &#123;\"health\": \"true\"&#125; etcd-1 Healthy &#123;\"health\": \"true\"&#125; [root@k8s-m1 kubernetes]# kubectl get svckubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 23h[root@k8s-m1 kubernetes]# kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s-m1 NotReady master 52s v1.11.1k8s-m2 NotReady master 51s v1.11.1k8s-m3 NotReady master 50s v1.11.1[root@k8s-m1 kubernetes]# kubectl -n kube-system get poNAME READY STATUS RESTARTS AGEetcd-k8s-m1 1/1 Running 0 7metcd-k8s-m2 1/1 Running 0 8metcd-k8s-m3 1/1 Running 0 7mhaproxy-k8s-m1 1/1 Running 0 7mhaproxy-k8s-m2 1/1 Running 0 8mhaproxy-k8s-m3 1/1 Running 0 8mkeepalived-k8s-m1 1/1 Running 0 8mkeepalived-k8s-m2 1/1 Running 0 7mkeepalived-k8s-m3 1/1 Running 0 7mkube-apiserver-k8s-m1 1/1 Running 0 7mkube-apiserver-k8s-m2 1/1 Running 0 6mkube-apiserver-k8s-m3 1/1 Running 0 7mkube-controller-manager-k8s-m1 1/1 Running 0 8mkube-controller-manager-k8s-m2 1/1 Running 0 8mkube-controller-manager-k8s-m3 1/1 Running 0 8mkube-scheduler-k8s-m1 1/1 Running 0 8mkube-scheduler-k8s-m2 1/1 Running 0 8mkube-scheduler-k8s-m3 1/1 Running 0 8m 启用 Bootstrap Tokens 认证 12345678cd ~/ansible-kubernetes-v1.11.1-ipvsansible-playbook tls-bootstrap-autoapprove-RBAC.yml# 查看csr[root@k8s-m1 ansible-kubernetes-v1.11.1-ipvs]# kubectl get csrNAME AGE REQUESTOR CONDITIONcsr-5l8dr 1m system:node:k8s-m3 Approved,Issuedcsr-chcb4 1m system:node:k8s-m2 Approved,Issuedcsr-sb9f6 1m system:node:k8s-m1 Approved,Issued 至此 kubernetes 三节点HA的master部署完毕 添加node节点 默认添加hosts文件中的[Node] 熟悉的host 1234cd ~/ansible-kubernetes-v1.11.1-ipvs#请保证执行以前脚本前hosts中[Node] 属性没有已经添加过的节点 ansible-playbook add-node.yml#成功添加节点之后 请注释掉hosts中的所有节点 下次新增节点的时候 继续追加host即可 添加插件 所有插件都使用容器进行部署 部署kube-proxy 插件 如clusterCIDR 有改动 请替换掉 ‘10.244.0.0/16’ 将 ${https://vip:6443} 替换成为 group_vars/all.yml 中的vip 如 vip = 192.168.0.110 则 ${https://vip:6443} 替换为 https://192.168.0.110:6443 替换完成之后 新建一个kube-proxy.yml的文件 写入替换之后的内容 在任意master上执行 kubectl apply -f kube-proxy.yml 即可完成proxy的部署123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149#kub-proxy.yml# 镜像 registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.1apiVersion: v1kind: ServiceAccountmetadata: name: kube-proxy namespace: kube-system labels: addonmanager.kubernetes.io/mode: Reconcile---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: system:kube-proxy labels: addonmanager.kubernetes.io/mode: Reconcilesubjects:- kind: ServiceAccount name: kube-proxy namespace: kube-systemroleRef: kind: ClusterRole name: system:node-proxier apiGroup: rbac.authorization.k8s.io---apiVersion: v1kind: ConfigMapmetadata: labels: app: kube-proxy name: kube-proxy namespace: kube-systemdata: config.conf: |- apiVersion: kubeproxy.config.k8s.io/v1alpha1 bindAddress: 0.0.0.0 clientConnection: acceptContentTypes: \"\" burst: 10 contentType: application/vnd.kubernetes.protobuf kubeconfig: /var/lib/kube-proxy/kubeconfig.conf qps: 5 clusterCIDR: '10.244.0.0/16' configSyncPeriod: 15m0s conntrack: max: null maxPerCore: 32768 min: 131072 tcpCloseWaitTimeout: 1h0m0s tcpEstablishedTimeout: 24h0m0s enableProfiling: false healthzBindAddress: 0.0.0.0:10256 hostnameOverride: \"\" iptables: masqueradeAll: false masqueradeBit: 14 minSyncPeriod: 0s syncPeriod: 30s ipvs: masqueradeAll: true minSyncPeriod: 5s scheduler: \"rr\" syncPeriod: 30s kind: KubeProxyConfiguration metricsBindAddress: 127.0.0.1:10249 mode: \"ipvs\" nodePortAddresses: null oomScoreAdj: -999 portRange: \"\" resourceContainer: /kube-proxy udpIdleTimeout: 250ms kubeconfig.conf: |- apiVersion: v1 kind: Config clusters: - cluster: certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt server: $&#123;https://vip:6443&#125; name: default contexts: - context: cluster: default namespace: default user: default name: default current-context: default users: - name: default user: tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token---apiVersion: apps/v1kind: DaemonSetmetadata: labels: k8s-app: kube-proxy name: kube-proxy namespace: kube-systemspec: selector: matchLabels: k8s-app: kube-proxy template: metadata: labels: k8s-app: kube-proxy spec: tolerations: - effect: NoSchedule key: node-role.kubernetes.io/master - effect: NoSchedule key: node.cloudprovider.kubernetes.io/uninitialized value: \"true\" hostNetwork: true restartPolicy: Always serviceAccount: kube-proxy serviceAccountName: kube-proxy containers: - name: kube-proxy image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy-amd64:v1.11.1 command: - /usr/local/bin/kube-proxy - --config=/var/lib/kube-proxy/config.conf - --v=2 imagePullPolicy: IfNotPresent securityContext: privileged: true volumeMounts: - mountPath: /var/lib/kube-proxy name: kube-proxy - mountPath: /run/xtables.lock name: xtables-lock - mountPath: /lib/modules name: lib-modules readOnly: true volumes: - configMap: defaultMode: 420 name: kube-proxy name: kube-proxy - hostPath: path: /run/xtables.lock type: FileOrCreate name: xtables-lock - hostPath: path: /lib/modules name: lib-modules 部署flannel 插件 如Network 有改动 请替换掉 ‘10.244.0.0/16’ 在任意master上 新建一个kube-flannel.yml的文件 kubectl apply -f kube-flannel.yml 即可完成flannel的部署 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#kube-flannel.yml# 镜像 quay.io/coreos/flannel:v0.10.0-amd64---kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: flannelrules:- apiGroups: - \"\" resources: - pods verbs: - get- apiGroups: - \"\" resources: - nodes verbs: - list - watch- apiGroups: - \"\" resources: - nodes/status verbs: - patch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: flannelroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannelsubjects:- kind: ServiceAccount name: flannel namespace: kube-system---apiVersion: v1kind: ServiceAccountmetadata: name: flannel namespace: kube-system---kind: ConfigMapapiVersion: v1metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flanneldata: cni-conf.json: | &#123; \"name\": \"cbr0\", \"plugins\": [ &#123; \"type\": \"flannel\", \"delegate\": &#123; \"hairpinMode\": true, \"isDefaultGateway\": true &#125; &#125;, &#123; \"type\": \"portmap\", \"capabilities\": &#123; \"portMappings\": true &#125; &#125; ] &#125; net-conf.json: | &#123; \"Network\": \"10.244.0.0/16\", \"Backend\": &#123; \"Type\": \"vxlan\" &#125; &#125;---apiVersion: extensions/v1beta1kind: DaemonSetmetadata: name: kube-flannel-ds namespace: kube-system labels: tier: node app: flannelspec: template: metadata: labels: tier: node app: flannel spec: hostNetwork: true nodeSelector: beta.kubernetes.io/arch: amd64 tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.10.0-amd64 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.10.0-amd64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \"100m\" memory: \"50Mi\" limits: cpu: \"100m\" memory: \"50Mi\" securityContext: privileged: true env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg 部署coredns coredns.yml 无法直接使用需要填入自己的dnsip 故使用coredns.yaml.sed+deploy.sh 完成yml文件的生成 新建如下两个文件 给deploy +x 执行权限 ./deploy.sh -i ${ClusterDns} 这里的ClusterDns 取group_vars/all.yml中的ClusterDns即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# deploy.sh #!/bin/bash# Deploys CoreDNS to a cluster currently running Kube-DNS.show_help () &#123;cat &lt;&lt; USAGEusage: $0 [ -r REVERSE-CIDR ] [ -i DNS-IP ] [ -d CLUSTER-DOMAIN ] [ -t YAML-TEMPLATE ] -r : Define a reverse zone for the given CIDR. You may specifcy this option more than once to add multiple reverse zones. If no reverse CIDRs are defined, then the default is to handle all reverse zones (i.e. in-addr.arpa and ip6.arpa) -i : Specify the cluster DNS IP address. If not specificed, the IP address of the existing \"kube-dns\" service is used, if present.USAGEexit 0&#125;# Simple DefaultsCLUSTER_DOMAIN=cluster.localYAML_TEMPLATE=`pwd`/coredns.yaml.sed# Get Optswhile getopts \"hr:i:d:t:\" opt; do case \"$opt\" in h) show_help ;; r) REVERSE_CIDRS=\"$REVERSE_CIDRS $OPTARG\" ;; i) CLUSTER_DNS_IP=$OPTARG ;; d) CLUSTER_DOMAIN=$OPTARG ;; t) YAML_TEMPLATE=$OPTARG ;; esacdone# Conditional Defaultsif [[ -z $REVERSE_CIDRS ]]; then REVERSE_CIDRS=\"in-addr.arpa ip6.arpa\"fiif [[ -z $CLUSTER_DNS_IP ]]; then # Default IP to kube-dns IP CLUSTER_DNS_IP=$(kubectl get service --namespace kube-system kube-dns -o jsonpath=\"&#123;.spec.clusterIP&#125;\") if [ $? -ne 0 ]; then &gt;&amp;2 echo \"Error! The IP address for DNS service couldn't be determined automatically. Please specify the DNS-IP with the '-i' option.\" exit 2 fifised -e s/CLUSTER_DNS_IP/$CLUSTER_DNS_IP/g -e s/CLUSTER_DOMAIN/$CLUSTER_DOMAIN/g -e \"s?REVERSE_CIDRS?$REVERSE_CIDRS?g\" $YAML_TEMPLATE 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158#coredns.yaml.sedapiVersion: v1kind: ServiceAccountmetadata: name: coredns namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: labels: kubernetes.io/bootstrapping: rbac-defaults name: system:corednsrules:- apiGroups: - \"\" resources: - endpoints - services - pods - namespaces verbs: - list - watch---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" labels: kubernetes.io/bootstrapping: rbac-defaults name: system:corednsroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:corednssubjects:- kind: ServiceAccount name: coredns namespace: kube-system---apiVersion: v1kind: ConfigMapmetadata: name: coredns namespace: kube-systemdata: Corefile: | .:53 &#123; errors health kubernetes CLUSTER_DOMAIN REVERSE_CIDRS &#123; pods insecure upstream fallthrough in-addr.arpa ip6.arpa &#125; prometheus :9153 proxy . /etc/resolv.conf cache 30 reload loadbalance &#125;---apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: coredns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/name: \"CoreDNS\"spec: replicas: 2 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 selector: matchLabels: k8s-app: kube-dns template: metadata: labels: k8s-app: kube-dns spec: serviceAccountName: coredns tolerations: - key: \"CriticalAddonsOnly\" operator: \"Exists\" containers: - name: coredns image: coredns/coredns:1.2.0 imagePullPolicy: IfNotPresent args: [ \"-conf\", \"/etc/coredns/Corefile\" ] volumeMounts: - name: config-volume mountPath: /etc/coredns readOnly: true ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - containerPort: 9153 name: metrics protocol: TCP securityContext: allowPrivilegeEscalation: false capabilities: add: - NET_BIND_SERVICE drop: - all readOnlyRootFilesystem: true livenessProbe: httpGet: path: /health port: 8080 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 dnsPolicy: Default volumes: - name: config-volume configMap: name: coredns items: - key: Corefile path: Corefile---apiVersion: v1kind: Servicemetadata: name: kube-dns namespace: kube-system annotations: prometheus.io/port: \"9153\" prometheus.io/scrape: \"true\" labels: k8s-app: kube-dns kubernetes.io/cluster-service: \"true\" kubernetes.io/name: \"CoreDNS\"spec: selector: k8s-app: kube-dns clusterIP: CLUSTER_DNS_IP ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP 部署Dashboard 部署dashboard 插件 123kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml#查看部署情况kubectl -n kube-system get po,svc -l k8s-app=kubernetes-dashboard 创建open-api Cluster Role Binding 123456789101112131415cat &lt;&lt;EOF | kubectl create -f -apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: open-api namespace: \"\"roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - apiGroup: rbac.authorization.k8s.io kind: User name: system:anonymousEOF 创建dashboard service account 12kubectl -n kube-system create sa dashboardkubectl create clusterrolebinding dashboard --clusterrole cluster-admin --serviceaccount=kube-system:dashboard 获取login token 1kubectl -n kube-system describe secrets | sed -rn '/\\sdashboard-token-/,/^token/&#123;/^token/s#\\S+\\s+##p&#125;' dashboard url 地址 1https://&#123;vip&#125;:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ kubectl 自动补全1234yum install -y bash-completion source /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)可以将 source &lt;(kubectl completion bash) 命令 写入 $HOME/.bashrc中. 参考资料 https://zhangguanzhang.github.io/2018/05/05/Kubernetes_install/ https://github.com/zhangguanzhang/Kubernetes-ansible https://blog.csdn.net/weiyuefei/article/details/52595082 （IPVS） http://www.linuxvirtualserver.org/zh (LVS) https://mp.weixin.qq.com/s?__biz=MzU1OTAzNzc5MQ==&amp;mid=2247485610&amp;idx=1&amp;sn=e092e55c848af62368835d530c57da15&amp;chksm=fc1c249acb6bad8c940c587e59e0dc63ba4863c7063f0a0e322dcbd6ad5f610cd2ad1b4ba87d&amp;scene=21#wechat_redirect (ipvs VS iptables)","categories":[],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://qingmu.io/tags/微服务/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://qingmu.io/tags/kubernetes/"},{"name":"docker","slug":"docker","permalink":"https://qingmu.io/tags/docker/"}]}]}